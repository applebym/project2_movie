{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import dateutil.parser\n",
    "from pprint import pprint\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import urllib2, sys\n",
    "import string\n",
    "import gevent.monkey\n",
    "gevent.monkey.patch_socket()\n",
    "from gevent.pool import Pool\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods for BeautifulSoup ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_soup_ps(prefix, suffix):\n",
    "    response = requests.get(prefix + suffix)   \n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def get_soup_url(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods to gather data on given movie ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movie_value(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    if not obj: \n",
    "        return None\n",
    "    # this works for most of the values\n",
    "    next_sibling = obj.findNextSibling()\n",
    "    if next_sibling:\n",
    "        return next_sibling.text \n",
    "    else:\n",
    "        next_sibling = obj.find_parent().findNextSibling()\n",
    "        return next_sibling\n",
    "\n",
    "    \n",
    "def get_movie_values_odd(soup, field_name):\n",
    "    '''Grabs value from boxofficemojo HTML in \n",
    "    Domestic Summary box\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    try:\n",
    "        div_with_stats = soup.find_all('div',class_='mp_box_content')[1]\n",
    "        flag = False\n",
    "        obj = ''\n",
    "        for element in div_with_stats.find_all('td'):\n",
    "            if flag:\n",
    "                obj = element.text\n",
    "                return obj\n",
    "            if field_name in str(element):\n",
    "                flag = True\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "            \n",
    "def get_weekly_rev(soup):\n",
    "    '''Retrieves weekly revenue for given movie\n",
    "    \n",
    "    Returns a list of the weekly revenue,\n",
    "    ordered by week since release\n",
    "    '''\n",
    "    try:\n",
    "        weekly_rev_list = []\n",
    "        for element in soup.find_all('center')[1]:\n",
    "            box = element.find_all('font')\n",
    "            for thing in box:\n",
    "                if '$' in thing.text:\n",
    "                    clean_num = money_to_int(thing.text)\n",
    "                    weekly_rev_list.append(clean_num)\n",
    "        if weekly_rev_list[0] == weekly_rev_list[1]:\n",
    "            return weekly_rev_list[3::3]\n",
    "        else:\n",
    "            return weekly_rev_list[1::3]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def to_date(datestring):\n",
    "    try:\n",
    "        date = dateutil.parser.parse(datestring)\n",
    "        return date\n",
    "    except:\n",
    "        return datestring\n",
    "    \n",
    "\n",
    "def money_to_int(moneystring):\n",
    "    try:\n",
    "        moneystring = moneystring.replace('$', '').replace(',', '')\n",
    "        if 'mil' in moneystring:\n",
    "            moneystring_digits = moneystring.split(' ')[0].strip()\n",
    "            return int(moneystring_digits) * 1000000\n",
    "        return int(moneystring)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def runtime_to_minutes(runtimestring):\n",
    "    try:\n",
    "        runtime = runtimestring.split()\n",
    "        minutes = int(runtime[0])*60 + int(runtime[2])\n",
    "        return minutes\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    \n",
    "def theaters_to_int(theaterstring):\n",
    "    try:\n",
    "        theaters = int(str(theaterstring.split()[0]).replace(',',''))\n",
    "        return theaters\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def release_time_to_days(releasestring):\n",
    "    try:\n",
    "        days = int(releasestring.split()[0])\n",
    "        return days\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather the links to the top movies of all time ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_prefix = 'http://www.boxofficemojo.com/alltime/domestic.htm?page=' \n",
    "partial_movie_suffix = '&p=.htm'\n",
    "top_movie_links = set()\n",
    "\n",
    "for page in range(1,41):\n",
    "    full_movie_suffix = str(page) + partial_movie_suffix\n",
    "    soup = get_soup_ps(movie_prefix, full_movie_suffix)\n",
    "    for element in soup.find_all('a'):\n",
    "        link = element.get('href')\n",
    "        if link.startswith('/movies/?id'):\n",
    "            top_movie_links.add(link)\n",
    "    if '/movies/?id=michelledarnell.htm' in top_movie_links:\n",
    "        top_movie_links.remove('/movies/?id=michelledarnell.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3903\n"
     ]
    }
   ],
   "source": [
    "# Number of movies in database\n",
    "print len(top_movie_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'/movies/?id=planes.htm', u'/movies/?id=planes2.htm', u'/movies/?id=planestrainsandautomobiles.htm'])\n"
     ]
    }
   ],
   "source": [
    "# Smaller set of movies to test data collection on\n",
    "test_movie_links = {x for x in top_movie_links if 'planes' in x}\n",
    "print test_movie_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data from BoxOfficeMojo ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is a list of dictionaries containing all data for a single movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n"
     ]
    }
   ],
   "source": [
    "headers = ['movieid','movie title', 'domestic total gross',\n",
    "           'release date', 'runtime (mins)', 'rating', \n",
    "           'genre', 'production budget', 'distributor',\n",
    "            'opening weekend revenue', 'number of theaters',\n",
    "            'time in theaters (days)']\n",
    "\n",
    "base_url = 'http://www.boxofficemojo.com/'\n",
    "\n",
    "movie_data = []\n",
    "rev_data = {}\n",
    "missing_links = []\n",
    "\n",
    "counter = 1\n",
    "\n",
    "time_count = 0\n",
    "\n",
    "for movie in list(top_movie_links):\n",
    "    try:\n",
    "        if time_count % 50 == 0: print time_count\n",
    "        time_count += 1\n",
    "\n",
    "        # Create a movieid\n",
    "        movieid = counter\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "        # Create dictionary of movieid to list of weekly revenues\n",
    "        movie_link_split = movie.split('?')\n",
    "        weekly_suffix = movie_link_split[0] + '?page=weekly&' + movie_link_split[1]\n",
    "        weekly_soup = get_soup_ps(base_url, weekly_suffix)\n",
    "\n",
    "        weekly_revenue = get_weekly_rev(weekly_soup)\n",
    "\n",
    "        rev_data[movieid] = weekly_revenue\n",
    "\n",
    "\n",
    "        # Create list of movie data dictionarys\n",
    "        soup = get_soup_ps(base_url, movie)\n",
    "        adj_soup = get_soup_ps(base_url, movie + '&adjust_yr=2016&p=.htm')\n",
    "\n",
    "        raw_title_string = soup.find('title').text\n",
    "        title = raw_title_string.split('(')[0].strip()\n",
    "\n",
    "        raw_release_date = get_movie_value(soup,'Release Date')\n",
    "        release_date = to_date(raw_release_date)\n",
    "\n",
    "        raw_domestic_total_gross = get_movie_value(adj_soup,'Domestic Total')\n",
    "        domestic_total_gross = money_to_int(raw_domestic_total_gross)\n",
    "\n",
    "        raw_runtime = get_movie_value(soup,'Runtime')\n",
    "        runtime = runtime_to_minutes(raw_runtime)\n",
    "\n",
    "        rating = get_movie_value(soup,'MPAA Rating')\n",
    "\n",
    "        genre = get_movie_value(soup, 'Genre:')\n",
    "\n",
    "        raw_prod_budget = get_movie_value(soup, 'Production Budget')\n",
    "        prod_budget = money_to_int(raw_prod_budget)\n",
    "\n",
    "        distributor = get_movie_value(soup, 'Distributor:')\n",
    "\n",
    "        raw_opening_weekend = get_movie_values_odd(adj_soup, 'Opening')\n",
    "        opening_weekend = money_to_int(raw_opening_weekend)\n",
    "\n",
    "        raw_widest_release = get_movie_values_odd(soup, 'Widest')\n",
    "        widest_release = theaters_to_int(raw_widest_release)\n",
    "\n",
    "        raw_realease_time = get_movie_values_odd(soup, 'In Release')\n",
    "        release_time = release_time_to_days(raw_realease_time)\n",
    "\n",
    "        raw_close_date = get_movie_values_odd(soup, 'Close')\n",
    "        close_date = to_date(raw_close_date)\n",
    "\n",
    "        # Calculate days in theaters if not given\n",
    "        if release_time == None and close_date != None:\n",
    "            day_diff = close_date - release_date\n",
    "            release_time = release_time_to_days(str(day_diff))\n",
    "        elif release_time == None and close_date == None and weekly_revenue != None:\n",
    "            num_weeks = len(weekly_revenue)\n",
    "            release_time = num_weeks * 7\n",
    "\n",
    "\n",
    "\n",
    "        movie_dict = dict(zip(headers, [movieid, \n",
    "                                        title,\n",
    "                                        domestic_total_gross,\n",
    "                                        release_date,\n",
    "                                        runtime,\n",
    "                                        rating,\n",
    "                                        genre,\n",
    "                                        prod_budget,\n",
    "                                        distributor,\n",
    "                                        opening_weekend,\n",
    "                                        widest_release,\n",
    "                                        release_time]))\n",
    "\n",
    "        movie_data.append(movie_dict) \n",
    "    \n",
    "    except:\n",
    "        print 'ChunkedEncodingError'\n",
    "        missing_links.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [4934, 5692, 5092, 3050, 2618, 1822, 1592, 1251], 2: [10639, 9349, 9011, 7849, 5817, 4080, 3556, 2798, 1903, 1726], 3: [5325, 2944, 1842, 1211, 759, 763, 607, 465, 430, 397, 420, 485, 691, 480, 421], 4: [6324, 3495, 2855, 1455, 1200, 1055, 650, 605, 580], 5: [7924, 5851, 3130, 2759, 4243, 3014, 2248, 1730, 1349, 1196], 6: [43292, 41573, 5905, 4385, 3507, 3075, 2329], 7: [7709, 4813, 2411, 1659, 1120, 930, 794, 659, 2182, 1192, 1008, 1519, 1022, 1548], 8: [2181, 2530, 1190, 1172], 9: [7463, 6550, 7799, 5877, 3927, 2917, 2316, 1860, 1667], 10: [12665, 7955, 4965, 2985, 2017, 1999, 1181, 1037]}\n",
      "[{'rating': u'PG', 'time in theaters (days)': 56, 'movieid': 1, 'production budget': None, 'domestic total gross': 90944400, 'number of theaters': 1515, 'opening weekend revenue': 8129500, 'distributor': u'Orion Pictures', 'movie title': u'Dirty Rotten Scoundrels', 'genre': u'Comedy', 'release date': datetime.datetime(1988, 12, 16, 0, 0), 'runtime (mins)': 110}, {'rating': u'R', 'time in theaters (days)': 70, 'movieid': 2, 'production budget': 30000000, 'domestic total gross': 252358600, 'number of theaters': 2169, 'opening weekend revenue': 30088300, 'distributor': u'Fox', 'movie title': u'Speed', 'genre': u'Action Thriller', 'release date': datetime.datetime(1994, 6, 10, 0, 0), 'runtime (mins)': 116}, {'rating': u'PG-13', 'time in theaters (days)': 105, 'movieid': 3, 'production budget': 75000000, 'domestic total gross': 48884600, 'number of theaters': 2128, 'opening weekend revenue': 14084800, 'distributor': u'Paramount', 'movie title': u'The Out-of-Towners', 'genre': u'Comedy', 'release date': datetime.datetime(1999, 4, 2, 0, 0), 'runtime (mins)': 90}, {'rating': u'R', 'time in theaters (days)': 63, 'movieid': 4, 'production budget': 57000000, 'domestic total gross': 39263600, 'number of theaters': 1612, 'opening weekend revenue': 11081500, 'distributor': u'Universal', 'movie title': u\"Captain Corelli's Mandolin\", 'genre': u'War Romance', 'release date': datetime.datetime(2001, 8, 17, 0, 0), 'runtime (mins)': 129}, {'rating': u'R', 'time in theaters (days)': 70, 'movieid': 5, 'production budget': None, 'domestic total gross': 108640100, 'number of theaters': 1684, 'opening weekend revenue': 15596500, 'distributor': u'Paramount', 'movie title': u'Planes, Trains and Automobiles', 'genre': u'Comedy', 'release date': datetime.datetime(1987, 11, 25, 0, 0), 'runtime (mins)': 92}, {'rating': u'R', 'time in theaters (days)': 49, 'movieid': 6, 'production budget': None, 'domestic total gross': 32374700, 'number of theaters': 635, 'opening weekend revenue': None, 'distributor': u'Triumph', 'movie title': u'Avalon', 'genre': u'Period Drama', 'release date': datetime.datetime(1990, 10, 5, 0, 0), 'runtime (mins)': 128}, {'rating': u'PG-13', 'time in theaters (days)': 112, 'movieid': 7, 'production budget': None, 'domestic total gross': 55006600, 'number of theaters': 2256, 'opening weekend revenue': 19482600, 'distributor': u'DreamWorks', 'movie title': u'Head of State', 'genre': u'Comedy', 'release date': datetime.datetime(2003, 3, 28, 0, 0), 'runtime (mins)': 95}, {'rating': u'PG', 'time in theaters (days)': 28, 'movieid': 8, 'production budget': None, 'domestic total gross': 39524000, 'number of theaters': 2419, 'opening weekend revenue': 8285700, 'distributor': u'Universal', 'movie title': u'Flipper', 'genre': u'Family Adventure', 'release date': datetime.datetime(1996, 5, 17, 0, 0), 'runtime (mins)': 97}, {'rating': u'R', 'time in theaters (days)': 63, 'movieid': 9, 'production budget': None, 'domestic total gross': 94767400, 'number of theaters': 989, 'opening weekend revenue': 9133000, 'distributor': u'Fox', 'movie title': u'Wall Street', 'genre': u'Drama', 'release date': datetime.datetime(1987, 12, 11, 0, 0), 'runtime (mins)': 125}, {'rating': u'PG-13', 'time in theaters (days)': 56, 'movieid': 10, 'production budget': 55000000, 'domestic total gross': 122476400, 'number of theaters': 1866, 'opening weekend revenue': 25388000, 'distributor': u'Universal', 'movie title': u'Death Becomes Her', 'genre': u'Horror Comedy', 'release date': datetime.datetime(1992, 7, 31, 0, 0), 'runtime (mins)': 103}]\n"
     ]
    }
   ],
   "source": [
    "test_rev_data = {k: rev_data[k] for k in rev_data.keys()[:10]}\n",
    "print (test_rev_data)\n",
    "print (movie_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print len(missing_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3903\n",
      "3903\n",
      "671\n"
     ]
    }
   ],
   "source": [
    "# Check that the data is all there\n",
    "print len(rev_data)\n",
    "print len(movie_data)\n",
    "\n",
    "# Sanity check what the longest list is\n",
    "max_count = 0\n",
    "for movid,weekly_list in rev_data.items():\n",
    "    try:\n",
    "        count = len(weekly_list)\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "    except:\n",
    "        continue\n",
    "print max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('movie_data2.pickle', 'wb') as handle:\n",
    "#     pickle.dump(movie_data, handle)\n",
    "\n",
    "# with open('rev_data2.pickle', 'wb') as handle:\n",
    "#     pickle.dump(movie_data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('movie_data3.pickle', 'wb') as handle:\n",
    "#     pickle.dump(movie_data, handle)\n",
    "\n",
    "# with open('rev_data3.pickle', 'wb') as handle:\n",
    "#     pickle.dump(rev_data, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input movie data into pandas DataFrame #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moviedf = pd.DataFrame(movie_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributor                        object\n",
      "domestic total gross              float64\n",
      "genre                              object\n",
      "movie title                        object\n",
      "movieid                             int64\n",
      "number of theaters                float64\n",
      "opening weekend revenue           float64\n",
      "production budget                 float64\n",
      "rating                             object\n",
      "release date               datetime64[ns]\n",
      "runtime (mins)                    float64\n",
      "time in theaters (days)           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print moviedf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distributor                3900\n",
       "domestic total gross       3900\n",
       "genre                      3900\n",
       "movie title                3903\n",
       "movieid                    3903\n",
       "number of theaters         3632\n",
       "opening weekend revenue    3297\n",
       "production budget          2025\n",
       "rating                     3900\n",
       "release date               3900\n",
       "runtime (mins)             3899\n",
       "time in theaters (days)    3654\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviedf.count(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domestic total gross</th>\n",
       "      <th>movieid</th>\n",
       "      <th>number of theaters</th>\n",
       "      <th>opening weekend revenue</th>\n",
       "      <th>production budget</th>\n",
       "      <th>runtime (mins)</th>\n",
       "      <th>time in theaters (days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.900000e+03</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3.297000e+03</td>\n",
       "      <td>2.025000e+03</td>\n",
       "      <td>3899.000000</td>\n",
       "      <td>3654.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.625383e+07</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>2230.817181</td>\n",
       "      <td>2.354510e+07</td>\n",
       "      <td>5.487065e+07</td>\n",
       "      <td>108.427289</td>\n",
       "      <td>93.705255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.894027e+07</td>\n",
       "      <td>1126.843379</td>\n",
       "      <td>933.700176</td>\n",
       "      <td>2.306523e+07</td>\n",
       "      <td>4.632437e+07</td>\n",
       "      <td>19.376241</td>\n",
       "      <td>175.692769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.263930e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.960000e+04</td>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.758938e+07</td>\n",
       "      <td>976.500000</td>\n",
       "      <td>1489.750000</td>\n",
       "      <td>1.054660e+07</td>\n",
       "      <td>2.200000e+07</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.257970e+07</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>2292.500000</td>\n",
       "      <td>1.649820e+07</td>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.153584e+08</td>\n",
       "      <td>2927.500000</td>\n",
       "      <td>2950.000000</td>\n",
       "      <td>2.766540e+07</td>\n",
       "      <td>7.500000e+07</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.239014e+09</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>4468.000000</td>\n",
       "      <td>2.479667e+08</td>\n",
       "      <td>3.000000e+08</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>4697.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       domestic total gross      movieid  number of theaters  \\\n",
       "count          3.900000e+03  3903.000000         3632.000000   \n",
       "mean           9.625383e+07  1952.000000         2230.817181   \n",
       "std            9.894027e+07  1126.843379          933.700176   \n",
       "min            1.263930e+07     1.000000            2.000000   \n",
       "25%            3.758938e+07   976.500000         1489.750000   \n",
       "50%            6.257970e+07  1952.000000         2292.500000   \n",
       "75%            1.153584e+08  2927.500000         2950.000000   \n",
       "max            1.239014e+09  3903.000000         4468.000000   \n",
       "\n",
       "       opening weekend revenue  production budget  runtime (mins)  \\\n",
       "count             3.297000e+03       2.025000e+03     3899.000000   \n",
       "mean              2.354510e+07       5.487065e+07      108.427289   \n",
       "std               2.306523e+07       4.632437e+07       19.376241   \n",
       "min               4.960000e+04       1.500000e+04       38.000000   \n",
       "25%               1.054660e+07       2.200000e+07       95.000000   \n",
       "50%               1.649820e+07       4.000000e+07      106.000000   \n",
       "75%               2.766540e+07       7.500000e+07      118.000000   \n",
       "max               2.479667e+08       3.000000e+08      227.000000   \n",
       "\n",
       "       time in theaters (days)  \n",
       "count              3654.000000  \n",
       "mean                 93.705255  \n",
       "std                 175.692769  \n",
       "min                   0.000000  \n",
       "25%                  42.000000  \n",
       "50%                  77.000000  \n",
       "75%                 112.000000  \n",
       "max                4697.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviedf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distributor</th>\n",
       "      <th>domestic total gross</th>\n",
       "      <th>genre</th>\n",
       "      <th>movie title</th>\n",
       "      <th>movieid</th>\n",
       "      <th>number of theaters</th>\n",
       "      <th>opening weekend revenue</th>\n",
       "      <th>production budget</th>\n",
       "      <th>rating</th>\n",
       "      <th>release date</th>\n",
       "      <th>runtime (mins)</th>\n",
       "      <th>time in theaters (days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>40405900.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Under the Sea 3D</td>\n",
       "      <td>29</td>\n",
       "      <td>108.0</td>\n",
       "      <td>771100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>2009-02-13</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Sony Classics</td>\n",
       "      <td>22447900.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Across the Sea of Time</td>\n",
       "      <td>491</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>1995-10-20</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>15663600.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>To the Arctic</td>\n",
       "      <td>667</td>\n",
       "      <td>52.0</td>\n",
       "      <td>289500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>2012-04-20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>IMAX</td>\n",
       "      <td>126001600.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Space Station 3-D</td>\n",
       "      <td>793</td>\n",
       "      <td>64.0</td>\n",
       "      <td>733000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>2002-04-19</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>Sony Classics</td>\n",
       "      <td>24348500.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Cirque du Soleil: Journey of Man</td>\n",
       "      <td>1106</td>\n",
       "      <td>22.0</td>\n",
       "      <td>80400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>2000-05-05</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>WGB.</td>\n",
       "      <td>23353700.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Shackleton's Antarctic Adventure</td>\n",
       "      <td>1188</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>2001-02-10</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1034.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>IMAX</td>\n",
       "      <td>82589700.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>T-Rex: Back to the Cretaceous</td>\n",
       "      <td>1230</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>1998-10-23</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>IMAX</td>\n",
       "      <td>26204200.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Galapagos</td>\n",
       "      <td>1318</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>1999-10-29</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>Buena Vista</td>\n",
       "      <td>24491000.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Ghosts of the Abyss</td>\n",
       "      <td>1622</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2032100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>2003-04-11</td>\n",
       "      <td>61.0</td>\n",
       "      <td>917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>57619400.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Deep Sea 3D</td>\n",
       "      <td>1665</td>\n",
       "      <td>47.0</td>\n",
       "      <td>930100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>2006-03-03</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>30148400.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>NASCAR 3D: The IMAX Experience</td>\n",
       "      <td>2022</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2035100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG</td>\n",
       "      <td>2004-03-12</td>\n",
       "      <td>40.0</td>\n",
       "      <td>644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>IMAX</td>\n",
       "      <td>19086900.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2111</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>1999-04-02</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>IMAX</td>\n",
       "      <td>43220300.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Magnificent Desolation</td>\n",
       "      <td>2384</td>\n",
       "      <td>82.0</td>\n",
       "      <td>650900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>2005-09-23</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>SK Films</td>\n",
       "      <td>25652500.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Bugs!</td>\n",
       "      <td>2404</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>2003-03-12</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1621.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>IMAX</td>\n",
       "      <td>68713900.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Mysteries of Egypt</td>\n",
       "      <td>2536</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>1998-08-21</td>\n",
       "      <td>38.0</td>\n",
       "      <td>871.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>National Geographic Entertainment</td>\n",
       "      <td>28824300.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Sea Monsters: A Prehistoric Adventure</td>\n",
       "      <td>2825</td>\n",
       "      <td>252.0</td>\n",
       "      <td>766000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>2007-10-05</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>N Wave</td>\n",
       "      <td>21683200.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Wild Safari 3D</td>\n",
       "      <td>2853</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>2005-04-08</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>Sony Classics</td>\n",
       "      <td>27881800.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Thrill Ride</td>\n",
       "      <td>2909</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>1997-07-11</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>Sony Classics</td>\n",
       "      <td>21721100.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Wings of Courage</td>\n",
       "      <td>2911</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>1995-04-21</td>\n",
       "      <td>40.0</td>\n",
       "      <td>630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>Heliograph</td>\n",
       "      <td>20065600.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Solarmax</td>\n",
       "      <td>2979</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>2000-09-15</td>\n",
       "      <td>38.0</td>\n",
       "      <td>822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>26677800.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Born to Be Wild</td>\n",
       "      <td>3099</td>\n",
       "      <td>208.0</td>\n",
       "      <td>940700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>2011-04-08</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>Sony Classics</td>\n",
       "      <td>54523100.0</td>\n",
       "      <td>Period Drama</td>\n",
       "      <td>Howards End</td>\n",
       "      <td>3213</td>\n",
       "      <td>547.0</td>\n",
       "      <td>110200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG</td>\n",
       "      <td>1992-03-13</td>\n",
       "      <td>140.0</td>\n",
       "      <td>580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>N Wave</td>\n",
       "      <td>18493800.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Haunted Castle</td>\n",
       "      <td>3315</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG</td>\n",
       "      <td>2001-02-23</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>55999500.0</td>\n",
       "      <td>IMAX</td>\n",
       "      <td>Hubble 3D</td>\n",
       "      <td>3492</td>\n",
       "      <td>151.0</td>\n",
       "      <td>452500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>2010-03-19</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            distributor  domestic total gross         genre  \\\n",
       "28                         Warner Bros.            40405900.0          IMAX   \n",
       "490                       Sony Classics            22447900.0          IMAX   \n",
       "666                        Warner Bros.            15663600.0          IMAX   \n",
       "792                                IMAX           126001600.0          IMAX   \n",
       "1105                      Sony Classics            24348500.0          IMAX   \n",
       "1187                               WGB.            23353700.0          IMAX   \n",
       "1229                               IMAX            82589700.0          IMAX   \n",
       "1317                               IMAX            26204200.0          IMAX   \n",
       "1621                        Buena Vista            24491000.0          IMAX   \n",
       "1664                       Warner Bros.            57619400.0          IMAX   \n",
       "2021                       Warner Bros.            30148400.0          IMAX   \n",
       "2110                               IMAX            19086900.0          IMAX   \n",
       "2383                               IMAX            43220300.0          IMAX   \n",
       "2403                           SK Films            25652500.0          IMAX   \n",
       "2535                               IMAX            68713900.0          IMAX   \n",
       "2824  National Geographic Entertainment            28824300.0          IMAX   \n",
       "2852                             N Wave            21683200.0          IMAX   \n",
       "2908                      Sony Classics            27881800.0          IMAX   \n",
       "2910                      Sony Classics            21721100.0          IMAX   \n",
       "2978                         Heliograph            20065600.0          IMAX   \n",
       "3098                       Warner Bros.            26677800.0          IMAX   \n",
       "3212                      Sony Classics            54523100.0  Period Drama   \n",
       "3314                             N Wave            18493800.0          IMAX   \n",
       "3491                       Warner Bros.            55999500.0          IMAX   \n",
       "\n",
       "                                movie title  movieid  number of theaters  \\\n",
       "28                         Under the Sea 3D       29               108.0   \n",
       "490                  Across the Sea of Time      491                 2.0   \n",
       "666                           To the Arctic      667                52.0   \n",
       "792                       Space Station 3-D      793                64.0   \n",
       "1105       Cirque du Soleil: Journey of Man     1106                22.0   \n",
       "1187       Shackleton's Antarctic Adventure     1188                26.0   \n",
       "1229          T-Rex: Back to the Cretaceous     1230                38.0   \n",
       "1317                              Galapagos     1318                14.0   \n",
       "1621                    Ghosts of the Abyss     1622                97.0   \n",
       "1664                            Deep Sea 3D     1665                47.0   \n",
       "2021         NASCAR 3D: The IMAX Experience     2022                73.0   \n",
       "2110                                Extreme     2111                21.0   \n",
       "2383                 Magnificent Desolation     2384                82.0   \n",
       "2403                                  Bugs!     2404                33.0   \n",
       "2535                     Mysteries of Egypt     2536                27.0   \n",
       "2824  Sea Monsters: A Prehistoric Adventure     2825               252.0   \n",
       "2852                         Wild Safari 3D     2853                21.0   \n",
       "2908                            Thrill Ride     2909                81.0   \n",
       "2910                       Wings of Courage     2911                11.0   \n",
       "2978                               Solarmax     2979                 6.0   \n",
       "3098                        Born to Be Wild     3099               208.0   \n",
       "3212                            Howards End     3213               547.0   \n",
       "3314                         Haunted Castle     3315                10.0   \n",
       "3491                              Hubble 3D     3492               151.0   \n",
       "\n",
       "      opening weekend revenue  production budget   rating release date  \\\n",
       "28                   771100.0                NaN        G   2009-02-13   \n",
       "490                       NaN                NaN        G   1995-10-20   \n",
       "666                  289500.0                NaN        G   2012-04-20   \n",
       "792                  733000.0                NaN  Unrated   2002-04-19   \n",
       "1105                  80400.0                NaN        G   2000-05-05   \n",
       "1187                      NaN                NaN        G   2001-02-10   \n",
       "1229                      NaN                NaN  Unrated   1998-10-23   \n",
       "1317                      NaN                NaN  Unrated   1999-10-29   \n",
       "1621                2032100.0                NaN        G   2003-04-11   \n",
       "1664                 930100.0                NaN        G   2006-03-03   \n",
       "2021                2035100.0                NaN       PG   2004-03-12   \n",
       "2110                      NaN                NaN  Unrated   1999-04-02   \n",
       "2383                 650900.0                NaN  Unrated   2005-09-23   \n",
       "2403                      NaN                NaN  Unrated   2003-03-12   \n",
       "2535                      NaN                NaN  Unrated   1998-08-21   \n",
       "2824                 766000.0                NaN  Unrated   2007-10-05   \n",
       "2852                      NaN                NaN  Unrated   2005-04-08   \n",
       "2908                      NaN                NaN        G   1997-07-11   \n",
       "2910                      NaN                NaN        G   1995-04-21   \n",
       "2978                      NaN                NaN  Unrated   2000-09-15   \n",
       "3098                 940700.0                NaN        G   2011-04-08   \n",
       "3212                 110200.0                NaN       PG   1992-03-13   \n",
       "3314                      NaN                NaN       PG   2001-02-23   \n",
       "3491                 452500.0                NaN        G   2010-03-19   \n",
       "\n",
       "      runtime (mins)  time in theaters (days)  \n",
       "28              40.0                   2310.0  \n",
       "490             51.0                   3142.0  \n",
       "666             40.0                   1127.0  \n",
       "792             46.0                   4697.0  \n",
       "1105            38.0                   1402.0  \n",
       "1187            40.0                   1034.0  \n",
       "1229            45.0                   3234.0  \n",
       "1317            40.0                   3794.0  \n",
       "1621            61.0                    917.0  \n",
       "1664            40.0                   2842.0  \n",
       "2021            40.0                    644.0  \n",
       "2110            40.0                   1525.0  \n",
       "2383            40.0                   2296.0  \n",
       "2403            40.0                   1621.0  \n",
       "2535            38.0                    871.0  \n",
       "2824            40.0                   1437.0  \n",
       "2852            45.0                   1210.0  \n",
       "2908            38.0                   2361.0  \n",
       "2910            40.0                    630.0  \n",
       "2978            38.0                    822.0  \n",
       "3098            40.0                   1512.0  \n",
       "3212           140.0                    580.0  \n",
       "3314            38.0                   2837.0  \n",
       "3491            43.0                   1946.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviedf[moviedf['time in theaters (days)'] > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell to look at outliers\n",
    "# m = moviedf[moviedf['movieid'] == 792]\n",
    "# print m\n",
    "moviedf = moviedf[moviedf['movie title'] != 'Red Dawn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moviedf[18:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moviedf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moviedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Additional Features ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moviedf['release month'] = moviedf['release date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distributor</th>\n",
       "      <th>domestic total gross</th>\n",
       "      <th>genre</th>\n",
       "      <th>movie title</th>\n",
       "      <th>movieid</th>\n",
       "      <th>number of theaters</th>\n",
       "      <th>opening weekend revenue</th>\n",
       "      <th>production budget</th>\n",
       "      <th>rating</th>\n",
       "      <th>release date</th>\n",
       "      <th>runtime (mins)</th>\n",
       "      <th>time in theaters (days)</th>\n",
       "      <th>release month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orion Pictures</td>\n",
       "      <td>90944400.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Dirty Rotten Scoundrels</td>\n",
       "      <td>1</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>8129500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG</td>\n",
       "      <td>1988-12-16</td>\n",
       "      <td>110.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fox</td>\n",
       "      <td>252358600.0</td>\n",
       "      <td>Action Thriller</td>\n",
       "      <td>Speed</td>\n",
       "      <td>2</td>\n",
       "      <td>2169.0</td>\n",
       "      <td>30088300.0</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1994-06-10</td>\n",
       "      <td>116.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paramount</td>\n",
       "      <td>48884600.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>The Out-of-Towners</td>\n",
       "      <td>3</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>14084800.0</td>\n",
       "      <td>75000000.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>1999-04-02</td>\n",
       "      <td>90.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universal</td>\n",
       "      <td>39263600.0</td>\n",
       "      <td>War Romance</td>\n",
       "      <td>Captain Corelli's Mandolin</td>\n",
       "      <td>4</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>11081500.0</td>\n",
       "      <td>57000000.0</td>\n",
       "      <td>R</td>\n",
       "      <td>2001-08-17</td>\n",
       "      <td>129.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paramount</td>\n",
       "      <td>108640100.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Planes, Trains and Automobiles</td>\n",
       "      <td>5</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>15596500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>1987-11-25</td>\n",
       "      <td>92.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distributor  domestic total gross            genre  \\\n",
       "0  Orion Pictures            90944400.0           Comedy   \n",
       "1             Fox           252358600.0  Action Thriller   \n",
       "2       Paramount            48884600.0           Comedy   \n",
       "3       Universal            39263600.0      War Romance   \n",
       "4       Paramount           108640100.0           Comedy   \n",
       "\n",
       "                      movie title  movieid  number of theaters  \\\n",
       "0         Dirty Rotten Scoundrels        1              1515.0   \n",
       "1                           Speed        2              2169.0   \n",
       "2              The Out-of-Towners        3              2128.0   \n",
       "3      Captain Corelli's Mandolin        4              1612.0   \n",
       "4  Planes, Trains and Automobiles        5              1684.0   \n",
       "\n",
       "   opening weekend revenue  production budget rating release date  \\\n",
       "0                8129500.0                NaN     PG   1988-12-16   \n",
       "1               30088300.0         30000000.0      R   1994-06-10   \n",
       "2               14084800.0         75000000.0  PG-13   1999-04-02   \n",
       "3               11081500.0         57000000.0      R   2001-08-17   \n",
       "4               15596500.0                NaN      R   1987-11-25   \n",
       "\n",
       "   runtime (mins)  time in theaters (days)  release month  \n",
       "0           110.0                     56.0           12.0  \n",
       "1           116.0                     70.0            6.0  \n",
       "2            90.0                    105.0            4.0  \n",
       "3           129.0                     63.0            8.0  \n",
       "4            92.0                     70.0           11.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input revenue data into pandas DataFrame ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "revdf = pd.DataFrame.from_dict({k : pd.Series(v) for k,v in rev_data.items()}, \n",
    "                                     orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>661</th>\n",
       "      <th>662</th>\n",
       "      <th>663</th>\n",
       "      <th>664</th>\n",
       "      <th>665</th>\n",
       "      <th>666</th>\n",
       "      <th>667</th>\n",
       "      <th>668</th>\n",
       "      <th>669</th>\n",
       "      <th>670</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4934</td>\n",
       "      <td>5692.0</td>\n",
       "      <td>5092.0</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10639</td>\n",
       "      <td>9349.0</td>\n",
       "      <td>9011.0</td>\n",
       "      <td>7849.0</td>\n",
       "      <td>5817.0</td>\n",
       "      <td>4080.0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>2798.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5325</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>1842.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6324</td>\n",
       "      <td>3495.0</td>\n",
       "      <td>2855.0</td>\n",
       "      <td>1455.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7924</td>\n",
       "      <td>5851.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>2759.0</td>\n",
       "      <td>4243.0</td>\n",
       "      <td>3014.0</td>\n",
       "      <td>2248.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0       1       2       3       4       5       6       7       8    \\\n",
       "1   4934  5692.0  5092.0  3050.0  2618.0  1822.0  1592.0  1251.0     NaN   \n",
       "2  10639  9349.0  9011.0  7849.0  5817.0  4080.0  3556.0  2798.0  1903.0   \n",
       "3   5325  2944.0  1842.0  1211.0   759.0   763.0   607.0   465.0   430.0   \n",
       "4   6324  3495.0  2855.0  1455.0  1200.0  1055.0   650.0   605.0   580.0   \n",
       "5   7924  5851.0  3130.0  2759.0  4243.0  3014.0  2248.0  1730.0  1349.0   \n",
       "\n",
       "      9   ...   661  662  663  664  665  666  667  668  669  670  \n",
       "1     NaN ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  1726.0 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3   397.0 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4     NaN ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "5  1196.0 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 671 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_list = revdf.index.tolist()\n",
    "print index_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert items to floats\n",
    "rev_list = []\n",
    "iterator = revdf.iterrows()\n",
    "for item in iterator:\n",
    "    num_list = []\n",
    "    for num in item[1]:\n",
    "        money = money_to_int(str(num))\n",
    "        num_list.append(money)\n",
    "    rev_list.append(num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revdf = pd.DataFrame(rev_list, index=index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "revdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print revdf.index.tolist()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "revdf.to_csv('csv/init_float_revdf.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# revdf_nulls = revdf[revdf.isnull().all(axis=1)]\n",
    "# revdf_nulls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weekly_rev_df.drop(791, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# weekly_rev_df.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weekly_rev_df.dropna(axis=0, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save DFs\n",
    "# moviedf.to_csv('csv/moviedf2.csv',encoding='utf-8')\n",
    "# weekly_rev_df.to_csv('csv/weekly_rev_df1.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Includes the movie indexes to include, where weekly revenue is not null\n",
    "# index_list = weekly_rev_df.index.tolist()\n",
    "# print index_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# moviedf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# moviedf_clean = moviedf[moviedf.index.isin(index_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# movie_index_list = moviedf_clean.index.tolist()\n",
    "# print movie_index_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print movie_index_list == index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(movie_index_list)\n",
    "# print len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(moviedf.index.tolist())\n",
    "print len(revdf.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "revdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revdf_exnullrows = revdf.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(revdf_exnullrows)\n",
    "revdf_exnullrows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ittr = revdf.iterrows()\n",
    "\n",
    "decay_rates = []\n",
    "for row in ittr:\n",
    "    rev_series = row[1]\n",
    "    a = rev_series[0]\n",
    "    t = rev_series.count()\n",
    "    y = rev_series[t-1]\n",
    "    k = (np.log(y) - np.log(a)) / t\n",
    "    decay_rates.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17152584832779882, -0.18187199018729922, -0.16916901045968302, -0.26545323275432192, -0.18909134733078653, -0.41750412421867089, -0.11467319302211353, -0.15526794901616792, -0.16654798604228807, -0.31281379427578093]\n"
     ]
    }
   ],
   "source": [
    "print decay_rates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revdf['decay rate'] = np.asarray(decay_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>662</th>\n",
       "      <th>663</th>\n",
       "      <th>664</th>\n",
       "      <th>665</th>\n",
       "      <th>666</th>\n",
       "      <th>667</th>\n",
       "      <th>668</th>\n",
       "      <th>669</th>\n",
       "      <th>670</th>\n",
       "      <th>decay rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4934</td>\n",
       "      <td>5692.0</td>\n",
       "      <td>5092.0</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.171526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10639</td>\n",
       "      <td>9349.0</td>\n",
       "      <td>9011.0</td>\n",
       "      <td>7849.0</td>\n",
       "      <td>5817.0</td>\n",
       "      <td>4080.0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>2798.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.181872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5325</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>1842.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.169169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6324</td>\n",
       "      <td>3495.0</td>\n",
       "      <td>2855.0</td>\n",
       "      <td>1455.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.265453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7924</td>\n",
       "      <td>5851.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>2759.0</td>\n",
       "      <td>4243.0</td>\n",
       "      <td>3014.0</td>\n",
       "      <td>2248.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.189091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8  \\\n",
       "1   4934  5692.0  5092.0  3050.0  2618.0  1822.0  1592.0  1251.0     NaN   \n",
       "2  10639  9349.0  9011.0  7849.0  5817.0  4080.0  3556.0  2798.0  1903.0   \n",
       "3   5325  2944.0  1842.0  1211.0   759.0   763.0   607.0   465.0   430.0   \n",
       "4   6324  3495.0  2855.0  1455.0  1200.0  1055.0   650.0   605.0   580.0   \n",
       "5   7924  5851.0  3130.0  2759.0  4243.0  3014.0  2248.0  1730.0  1349.0   \n",
       "\n",
       "        9     ...      662  663  664  665  666  667  668  669  670  decay rate  \n",
       "1     NaN     ...      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   -0.171526  \n",
       "2  1726.0     ...      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   -0.181872  \n",
       "3   397.0     ...      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   -0.169169  \n",
       "4     NaN     ...      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   -0.265453  \n",
       "5  1196.0     ...      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   -0.189091  \n",
       "\n",
       "[5 rows x 672 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(revdf[revdf['decay rate'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "revdf_exnullrows['decay rate'] = np.asarray(decay_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "revdf_exnullrows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_avgs = revdf_exnullrows.mean(axis=0)\n",
    "xs = np.arange(len(y_avgs))\n",
    "plt.plot(xs[:100], y_avgs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get rid of movies where there are over 100 weeks of revenue data (mostly IMAX movies)\n",
    "revdf_exoutliers = revdf_exnullrows[revdf_exnullrows.count(axis=1) < 100]\n",
    "len(revdf_exoutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moviedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test1 = pd.DataFrame({'title': ['a','b','c','d'], 'score': [4,3,3,5],'movieid': [1,2,4,6]})\n",
    "\n",
    "dd = {1: [11,23,23,2], 2:[121,14,123], 3:[12,21,1]}\n",
    "test2 = pd.DataFrame.from_dict({k : pd.Series(v) for k,v in dd.items()}, \n",
    "                                     orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test2['decay rate'] = np.asarray([0.2,-0.6,0.02])\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test3 = pd.concat([test2['decay rate'], test2.index], axis=1)\n",
    "# test3\n",
    "# result = pd.merge(test1, test2['decay rate'], left_on='movieid', right_on='movieid', how='inner')\n",
    "# result\n",
    "test2_short = pd.DataFrame(test2['decay rate'], index=test2.index)\n",
    "test2_short\n",
    "test3 = pd.merge(test1, test2_short, left_on='movieid', right_index=True, how='inner')\n",
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decay rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.171526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.181872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.169169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.265453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.189091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decay rate\n",
       "1   -0.171526\n",
       "2   -0.181872\n",
       "3   -0.169169\n",
       "4   -0.265453\n",
       "5   -0.189091"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decaydf = pd.DataFrame(revdf['decay rate'], index=revdf.index)\n",
    "decaydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domestic total gross</th>\n",
       "      <th>movieid</th>\n",
       "      <th>number of theaters</th>\n",
       "      <th>opening weekend revenue</th>\n",
       "      <th>production budget</th>\n",
       "      <th>runtime (mins)</th>\n",
       "      <th>time in theaters (days)</th>\n",
       "      <th>release month</th>\n",
       "      <th>decay rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.643000e+03</td>\n",
       "      <td>3643.000000</td>\n",
       "      <td>3616.000000</td>\n",
       "      <td>3.242000e+03</td>\n",
       "      <td>1.994000e+03</td>\n",
       "      <td>3642.000000</td>\n",
       "      <td>3643.000000</td>\n",
       "      <td>3643.000000</td>\n",
       "      <td>3643.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.957397e+07</td>\n",
       "      <td>1948.875377</td>\n",
       "      <td>2236.897677</td>\n",
       "      <td>2.372106e+07</td>\n",
       "      <td>5.548542e+07</td>\n",
       "      <td>107.799561</td>\n",
       "      <td>93.986001</td>\n",
       "      <td>6.974197</td>\n",
       "      <td>-0.202691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.587887e+07</td>\n",
       "      <td>1125.529929</td>\n",
       "      <td>928.836871</td>\n",
       "      <td>2.313544e+07</td>\n",
       "      <td>4.625888e+07</td>\n",
       "      <td>18.875513</td>\n",
       "      <td>175.883438</td>\n",
       "      <td>3.447081</td>\n",
       "      <td>0.148253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.263930e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.960000e+04</td>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.256936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.613510e+07</td>\n",
       "      <td>979.000000</td>\n",
       "      <td>1498.000000</td>\n",
       "      <td>1.064488e+07</td>\n",
       "      <td>2.300000e+07</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.274697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.966970e+07</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>2302.500000</td>\n",
       "      <td>1.657520e+07</td>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-0.202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.095184e+08</td>\n",
       "      <td>2918.500000</td>\n",
       "      <td>2952.250000</td>\n",
       "      <td>2.788838e+07</td>\n",
       "      <td>7.500000e+07</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-0.147904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.114286e+09</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>4468.000000</td>\n",
       "      <td>2.479667e+08</td>\n",
       "      <td>3.000000e+08</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>4697.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.143955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       domestic total gross      movieid  number of theaters  \\\n",
       "count          3.643000e+03  3643.000000         3616.000000   \n",
       "mean           8.957397e+07  1948.875377         2236.897677   \n",
       "std            8.587887e+07  1125.529929          928.836871   \n",
       "min            1.263930e+07     1.000000            2.000000   \n",
       "25%            3.613510e+07   979.000000         1498.000000   \n",
       "50%            5.966970e+07  1945.000000         2302.500000   \n",
       "75%            1.095184e+08  2918.500000         2952.250000   \n",
       "max            1.114286e+09  3903.000000         4468.000000   \n",
       "\n",
       "       opening weekend revenue  production budget  runtime (mins)  \\\n",
       "count             3.242000e+03       1.994000e+03     3642.000000   \n",
       "mean              2.372106e+07       5.548542e+07      107.799561   \n",
       "std               2.313544e+07       4.625888e+07       18.875513   \n",
       "min               4.960000e+04       1.500000e+04       38.000000   \n",
       "25%               1.064488e+07       2.300000e+07       95.000000   \n",
       "50%               1.657520e+07       4.000000e+07      105.000000   \n",
       "75%               2.788838e+07       7.500000e+07      118.000000   \n",
       "max               2.479667e+08       3.000000e+08      227.000000   \n",
       "\n",
       "       time in theaters (days)  release month   decay rate  \n",
       "count              3643.000000    3643.000000  3643.000000  \n",
       "mean                 93.986001       6.974197    -0.202691  \n",
       "std                 175.883438       3.447081     0.148253  \n",
       "min                   7.000000       1.000000    -1.256936  \n",
       "25%                  42.000000       4.000000    -0.274697  \n",
       "50%                  77.000000       7.000000    -0.202300  \n",
       "75%                 112.000000      10.000000    -0.147904  \n",
       "max                4697.000000      12.000000     1.143955  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(moviedf, decaydf, left_on='movieid', right_index=True, how='inner')\n",
    "merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-621b4cd00e66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'merged' is not defined"
     ]
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged.to_csv('csv/merged_table_4_20.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot data (density and scatter plots) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_kde(df, category):\n",
    "    dropped = df[category].dropna()\n",
    "    density = gaussian_kde(dropped)\n",
    "    xs = np.linspace(dropped.min(),dropped.max(),300)\n",
    "    ys = density(xs)\n",
    "    plt.plot(xs, ys)\n",
    "    plt.title('PDF of ' + category)\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_kde(merged, 'domestic total gross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_kde(merged, 'number of theaters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_kde(merged, 'opening weekend revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_kde(merged, 'production budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_kde(merged, 'runtime (mins)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_kde(merged, 'time in theaters (days)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_kde(merged, 'release month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_kde(merged, 'decay rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_bar(df, column):\n",
    "    ys = df[column].value_counts(normalize=True, sort=False)\n",
    "    xs = np.arange(len(ys))\n",
    "    plt.figure(figsize=(18,5))\n",
    "    plt.bar(xs, ys.values)\n",
    "    plt.xticks(xs, ys.index, rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_bar(merged, 'genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_bar(merged, 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_bar(merged, 'distributor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_scatter(df, category):\n",
    "    xs = df[category]\n",
    "    ys = df['decay rate']\n",
    "    plt.scatter(xs, ys)\n",
    "    plt.savefig('img/scatter'+category+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scatter(merged, 'domestic total gross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scatter(merged, 'number of theaters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scatter(merged, 'opening weekend revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scatter(merged, 'production budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scatter(merged, 'runtime (mins)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scatter(merged, 'time in theaters (days)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scatter(merged, 'release month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_scatter_categorical(df, category):\n",
    "    d = {}\n",
    "    i = 0\n",
    "    for c in df[category].unique():\n",
    "        d[c] = i\n",
    "        i += 1\n",
    "    copy = df.copy(deep=True)\n",
    "    copy[category + '_cat'] = copy[category].map(d)\n",
    "    xs = copy[category + '_cat']\n",
    "    ys = copy['decay rate']\n",
    "    plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scatter_categorical(merged, 'genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scatter_categorical(merged, 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scatter_categorical(merged, 'distributor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from patsy import dmatrices, dmatrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "renamed = merged.rename(columns={'distributor':'dist', 'domestic total gross': 'dom_tot_gross',\n",
    "                                'movie title': 'title', 'number of theaters': 'num_theaters',\n",
    "                                'opening weekend revenue': 'open_rev', 'production budget': \n",
    "                                'budget', 'release date': 'release', 'runtime (mins)': 'runtime',\n",
    "                                'time in theaters (days)': 'time_theaters', 'release month': 'month',\n",
    "                                'decay rate': 'decay'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renamed.to_csv('csv/analysisdf.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "renamed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = renamed['decay']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "renamed.drop('decay', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into reporting (30%) and training (70%)\n",
    "X_train, X_report, y_train, y_report = train_test_split(X, y, \n",
    "                                                        test_size = 0.3,\n",
    "                                                        random_state = 4444)\n",
    "\n",
    "# X_train['y_train'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training data into training (60%) and testing (40%) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,\n",
    "                                                       test_size = 0.4,\n",
    "                                                       random_state = 4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check lengths\n",
    "print 'Training: ' + str(len(X_train) == len(y_train))\n",
    "print 'Testing: ' + str(len(X_test) == len(y_test))\n",
    "print 'Reporting: ' + str(len(X_report) == len(y_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model: num_theaters, runtime, month, rating, genre ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_Xy(data, y_category, X_categories, intercept=True):\n",
    "    formula = y_category + ' ~ '\n",
    "    for c in X_categories:\n",
    "        formula = formula + c + ' + '\n",
    "    formula = formula[:-3]\n",
    "    if not(intercept):\n",
    "        formula = formula + ' - 1'\n",
    "    y, X = dmatrices(formula, data=data, return_type='dataframe')\n",
    "    return y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_1 = ['num_theaters','runtime','C(month)','rating','genre']\n",
    "y1_train, X1_train = create_Xy(X_train,'decay',features_1, intercept=False)\n",
    "y1_test, X1_test = create_Xy(X_train,'decay',features_1, intercept=False)\n",
    "y1_report, X1_report = create_Xy(X_train,'decay',features_1, intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_1 = sm.OLS(y1_train, X1_train)\n",
    "results_1 = model_1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y1_pred_test = results_1.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r2_1 = r2_score(y1_test, y1_pred_test)\n",
    "r2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjr2_1 = 1 - (1 - r2_1) * ((len(y1_test) - 1) / (len(y1_test) - len(X1_test.columns) - 1))\n",
    "adjr2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model: num_theaters, runtime, month, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_2 = ['num_theaters','runtime','C(month)','rating']\n",
    "y2_train, X2_train = create_Xy(X_train,'decay',features_2, intercept=False)\n",
    "y2_test, X2_test = create_Xy(X_train,'decay',features_2, intercept=False)\n",
    "y2_report, X2_report = create_Xy(X_train,'decay',features_2, intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2 = sm.OLS(y2_train, X2_train)\n",
    "results_2 = model_2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2_pred_test = results_2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r2_2 = r2_score(y2_test, y2_pred_test)\n",
    "r2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjr2_4 = 1 - (1 - r2_4) * ((len(y4_test) - 1) / (len(y4_test) - len(X4_test.columns) - 1))\n",
    "adjr2_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Model: num_theaters, runtime, month, genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_3 = ['num_theaters','runtime','C(month)','genre']\n",
    "y3_train, X3_train = create_Xy(X_train,'decay',features_3, intercept=False)\n",
    "y3_test, X3_test = create_Xy(X_train,'decay',features_3, intercept=False)\n",
    "y3_report, X3_report = create_Xy(X_train,'decay',features_3, intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_3 = sm.OLS(y3_train, X3_train)\n",
    "results_3 = model_3.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y3_pred_test = results_3.predict(X3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r2_3 = r2_score(y3_test, y3_pred_test)\n",
    "r2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjr2_3 = 1 - (1 - r2_3) * ((len(y3_test) - 1) / (len(y3_test) - len(X3_test.columns) - 1))\n",
    "adjr2_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Model: num_theaters, runtime, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_4 = ['num_theaters','runtime','C(month)']\n",
    "y4_train, X4_train = create_Xy(X_train,'decay',features_4, intercept=False)\n",
    "y4_test, X4_test = create_Xy(X_train,'decay',features_4, intercept=False)\n",
    "y4_report, X4_report = create_Xy(X_train,'decay',features_4, intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_4 = sm.OLS(y4_train, X4_train)\n",
    "results_4 = model_4.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y4_pred_test = results_4.predict(X4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r2_4 = r2_score(y4_test, y4_pred_test)\n",
    "r2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjr2_4 = 1 - (1 - r2_4) * ((len(y4_test) - 1) / (len(y4_test) - len(X4_test.columns) - 1))\n",
    "adjr2_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Minimum Viable Product Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Best model so far is Model 3\n",
    "# fig = plt.figure(figsize=(10,100))\n",
    "# fig = sm.graphics.plot_partregress_grid(results_3, fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,100))\n",
    "# fig = sm.graphics.plot_ccpr_grid(results_3, fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.set(style=\"darkgrid\", color_codes=True)\n",
    "# tips = sns.load_dataset(\"tips\")\n",
    "# g = sns.jointplot(\"total_bill\", \"tip\", data=tips, kind=\"reg\",\n",
    "#                   xlim=(0, 60), ylim=(0, 12), color=\"r\", size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = X3_train.columns.tolist()\n",
    "xlabels = []\n",
    "for item in columns[:-2]:\n",
    "    label = re.search('(?<=\\[).*(?=\\])', str(item)).group()\n",
    "    xlabels.append(label)\n",
    "xlabels.append(columns[-2])\n",
    "xlabels.append(columns[-1])\n",
    "\n",
    "formula = 'decay ~ num_theaters + runtime + C(month) + genre - 1'\n",
    "sns.set_context(\"poster\")\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "sns.coefplot(formula, X_train)\n",
    "plt.xticks(np.arange(len(columns)),xlabels, rotation=90, fontsize=10)\n",
    "\n",
    "ax = plt.gca()\n",
    "pos1 = ax.get_position()\n",
    "pos2 = [pos1.x0 - 0.05, pos1.y0 + 0.37,  pos1.width + 0.11, pos1.height - 0.4]\n",
    "ax.set_position(pos2)\n",
    "\n",
    "plt.title('Coefficients of Linear Regression Model', y=1.17)\n",
    "plt.suptitle('Adj. R-Squared of Model = 0.23 On Test Set', y=0.92)\n",
    "plt.xlabel('Independant Variables')\n",
    "plt.ylabel('Beta Coefficients')\n",
    "\n",
    "plt.savefig('img/mvp_coefplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.PairGrid(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = merged['release month']\n",
    "ys = merged['decay rate']\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(xs, ys)\n",
    "plt.title('Decay Rates by Release Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Decay Rate')\n",
    "\n",
    "ax = plt.gca()\n",
    "pos1 = ax.get_position()\n",
    "pos2 = [pos1.x0 + 0.02, pos1.y0 + 0.05,  pos1.width, pos1.height - 0.04]\n",
    "ax.set_position(pos2)\n",
    "\n",
    "plt.savefig('img/scatter_release_month.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(y3_pred_test, results_3.resid)\n",
    "plt.title('Fitted Y\\'s vs. Residuals')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals of Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "resid3_density = gaussian_kde(results_3.resid)\n",
    "xs = np.linspace(results_3.resid.min(),results_3.resid.max(),200)\n",
    "ys = resid3_density(xs)\n",
    "plt.plot(xs, ys)\n",
    "plt.title('PDF of resids')\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Resids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "het_white(results_3.resid, X3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ittr3 = X3_train.iterrows()\n",
    "# ypreds = []\n",
    "# for row in ittr3:\n",
    "#     y = results_3.predict(row)\n",
    "#     ypreds.append(y)\n",
    "# print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape MetaCritic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_meta_rating_moviepg(soup):\n",
    "    name_not_found = True\n",
    "    for item in soup.find_all('span'): \n",
    "        if item.get('itemprop') == 'ratingValue':\n",
    "            rating = item.text.strip()\n",
    "        if item.get('itemprop') == 'name' and (name_not_found):\n",
    "            title = item.text.strip()\n",
    "            name_not_found = False\n",
    "    return title, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philadelphia 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MelanieAppleby/anaconda/envs/benson/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Tester for single movie page\n",
    "meta_url = 'http://www.metacritic.com/movie/philadelphia'\n",
    "soup = get_soup_meta(meta_url)\n",
    "title, rating = get_meta_rating_moviepg(soup)\n",
    "print title, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_soup_url(url):\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=hdr)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'xml')\n",
    "    return soup\n",
    "\n",
    "def get_soup_meta(url):\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    req = urllib2.Request(url,headers=hdr)\n",
    "    page = urllib2.urlopen(req)\n",
    "    soup = BeautifulSoup(page)\n",
    "    return soup\n",
    "\n",
    "# def get_soup_url(url):\n",
    "#     pool = Pool(25)\n",
    "#     pool.spawn(requests.get, url)\n",
    "#     soup = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "#     return soup\n",
    "\n",
    "def get_soups(url_list):\n",
    "    pool = Pool(25)\n",
    "    soup_list = []\n",
    "    faulty_url_list = []\n",
    "    for link in url_list:\n",
    "        soup_list.append(pool.spawn(get_soup_url, link))\n",
    "    pool.join()\n",
    "    return soup_list\n",
    "\n",
    "def get_meta_url_list():\n",
    "    url_list = []\n",
    "    meta_base = 'http://www.metacritic.com/browse/movies/title/dvd' \n",
    "    alpha = [''] + list(string.ascii_lowercase)\n",
    "    for letter in alpha:\n",
    "        url = meta_base + '/' + letter + '?view=condensed'\n",
    "        url_list.append(url)\n",
    "        pages = np.arange(1,20)\n",
    "        for pg in pages: \n",
    "            url = meta_base + '/' + letter + '?view=condensed&page=' + str(pg)\n",
    "            url_list.append(url)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(url_list)\n",
    "# half = len(url_list)/2\n",
    "# print half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# meta_ratings_dict = defaultdict(str)\n",
    "\n",
    "# soup_list1 = get_soups(url_list[:half])\n",
    "# print 'Done with first set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# soup_list2 = get_soups(url_list[half:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print url_list[half:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n",
      "270\n",
      "0\n",
      "185\n"
     ]
    }
   ],
   "source": [
    "# print len(soup_list1)\n",
    "# print len(soup_list2)\n",
    "\n",
    "# empty_soups1 = [s for s in soup_list1 if s.value == None]\n",
    "# print len(empty_soups1)\n",
    "# empty_soups2 = [s for s in soup_list2 if s.value == None]\n",
    "# print len(empty_soups2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rerun soup retrieval for second half, but in halves\n",
    "# half2 = len(url_list[half:])/2\n",
    "# print len(url_list[:half])\n",
    "# print len(url_list[half:])\n",
    "# print half2\n",
    "# fake_url = 'http://www.metacritic.com/browse/movies/title/dvd/s?view=condensed&page=60'\n",
    "\n",
    "# soup_list2_1 = get_soups(url_list[:half2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(url_list)\n",
    "# soup_test = get_soup_meta(url_list[100])\n",
    "# print soup_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for soup: 1\n",
      "Fetching data for soup: 2\n",
      "Fetching data for soup: 3\n",
      "Fetching data for soup: 4\n",
      "Fetching data for soup: 5\n",
      "Fetching data for soup: 6\n",
      "Fetching data for soup: 7\n",
      "Fetching data for soup: 8\n",
      "Fetching data for soup: 9\n",
      "Fetching data for soup: 10\n",
      "Fetching data for soup: 11\n",
      "Fetching data for soup: 12\n",
      "Fetching data for soup: 13\n",
      "Fetching data for soup: 14\n",
      "Fetching data for soup: 15\n",
      "Fetching data for soup: 16\n",
      "Fetching data for soup: 17\n",
      "Fetching data for soup: 18\n",
      "Fetching data for soup: 19\n",
      "Fetching data for soup: 20\n",
      "Fetching data for soup: 21\n",
      "Fetching data for soup: 22\n",
      "Fetching data for soup: 23\n",
      "Fetching data for soup: 24\n",
      "Fetching data for soup: 25\n",
      "Fetching data for soup: 26\n",
      "Fetching data for soup: 27\n",
      "Fetching data for soup: 28\n",
      "Fetching data for soup: 29\n",
      "Fetching data for soup: 30\n",
      "Fetching data for soup: 31\n",
      "Fetching data for soup: 32\n",
      "Fetching data for soup: 33\n",
      "Fetching data for soup: 34\n",
      "Fetching data for soup: 35\n",
      "Fetching data for soup: 36\n",
      "Fetching data for soup: 37\n",
      "Fetching data for soup: 38\n",
      "Fetching data for soup: 39\n",
      "Fetching data for soup: 40\n",
      "Fetching data for soup: 41\n",
      "Fetching data for soup: 42\n",
      "Fetching data for soup: 43\n",
      "Fetching data for soup: 44\n",
      "Fetching data for soup: 45\n",
      "Fetching data for soup: 46\n",
      "Fetching data for soup: 47\n",
      "Fetching data for soup: 48\n",
      "Fetching data for soup: 49\n",
      "Fetching data for soup: 50\n",
      "Fetching data for soup: 51\n",
      "Fetching data for soup: 52\n",
      "Fetching data for soup: 53\n",
      "Fetching data for soup: 54\n",
      "Fetching data for soup: 55\n",
      "Fetching data for soup: 56\n",
      "Fetching data for soup: 57\n",
      "Fetching data for soup: 58\n",
      "Fetching data for soup: 59\n",
      "Fetching data for soup: 60\n",
      "Fetching data for soup: 61\n",
      "Fetching data for soup: 62\n",
      "Fetching data for soup: 63\n",
      "Fetching data for soup: 64\n",
      "Fetching data for soup: 65\n",
      "Fetching data for soup: 66\n",
      "Fetching data for soup: 67\n",
      "Fetching data for soup: 68\n",
      "Fetching data for soup: 69\n",
      "Fetching data for soup: 70\n",
      "Fetching data for soup: 71\n",
      "Fetching data for soup: 72\n",
      "Fetching data for soup: 73\n",
      "Fetching data for soup: 74\n",
      "Fetching data for soup: 75\n",
      "Fetching data for soup: 76\n",
      "Fetching data for soup: 77\n",
      "Fetching data for soup: 78\n",
      "Fetching data for soup: 79\n",
      "Fetching data for soup: 80\n",
      "Fetching data for soup: 81\n",
      "Fetching data for soup: 82\n",
      "Fetching data for soup: 83\n",
      "Fetching data for soup: 84\n",
      "Fetching data for soup: 85\n",
      "Fetching data for soup: 86\n",
      "Fetching data for soup: 87\n",
      "Fetching data for soup: 88\n",
      "Fetching data for soup: 89\n",
      "Fetching data for soup: 90\n",
      "Fetching data for soup: 91\n",
      "Fetching data for soup: 92\n",
      "Fetching data for soup: 93\n",
      "Fetching data for soup: 94\n",
      "Fetching data for soup: 95\n",
      "Fetching data for soup: 96\n",
      "Fetching data for soup: 97\n",
      "Fetching data for soup: 98\n",
      "Fetching data for soup: 99\n",
      "Fetching data for soup: 100\n",
      "Fetching data for soup: 101\n",
      "Fetching data for soup: 102\n",
      "Fetching data for soup: 103\n",
      "Fetching data for soup: 104\n",
      "Fetching data for soup: 105\n",
      "Fetching data for soup: 106\n",
      "Fetching data for soup: 107\n",
      "Fetching data for soup: 108\n",
      "Fetching data for soup: 109\n",
      "Fetching data for soup: 110\n",
      "Fetching data for soup: 111\n",
      "Fetching data for soup: 112\n",
      "Fetching data for soup: 113\n",
      "Fetching data for soup: 114\n",
      "Fetching data for soup: 115\n",
      "Fetching data for soup: 116\n",
      "Fetching data for soup: 117\n",
      "Fetching data for soup: 118\n",
      "Fetching data for soup: 119\n",
      "Fetching data for soup: 120\n",
      "Fetching data for soup: 121\n",
      "Fetching data for soup: 122\n",
      "Fetching data for soup: 123\n",
      "Fetching data for soup: 124\n",
      "Fetching data for soup: 125\n",
      "Fetching data for soup: 126\n",
      "Fetching data for soup: 127\n",
      "Fetching data for soup: 128\n",
      "Fetching data for soup: 129\n",
      "Fetching data for soup: 130\n",
      "Fetching data for soup: 131\n",
      "Fetching data for soup: 132\n",
      "Fetching data for soup: 133\n",
      "Fetching data for soup: 134\n",
      "Fetching data for soup: 135\n",
      "Fetching data for soup: 136\n",
      "Fetching data for soup: 137\n",
      "Fetching data for soup: 138\n",
      "Fetching data for soup: 139\n",
      "Fetching data for soup: 140\n",
      "Fetching data for soup: 141\n",
      "Fetching data for soup: 142\n",
      "Fetching data for soup: 143\n",
      "Fetching data for soup: 144\n",
      "Fetching data for soup: 145\n",
      "Fetching data for soup: 146\n",
      "Fetching data for soup: 147\n",
      "Fetching data for soup: 148\n",
      "Fetching data for soup: 149\n",
      "Fetching data for soup: 150\n",
      "Fetching data for soup: 151\n",
      "Fetching data for soup: 152\n",
      "Fetching data for soup: 153\n",
      "Fetching data for soup: 154\n",
      "Fetching data for soup: 155\n",
      "Fetching data for soup: 156\n",
      "Fetching data for soup: 157\n",
      "Fetching data for soup: 158\n",
      "Fetching data for soup: 159\n",
      "Fetching data for soup: 160\n",
      "Fetching data for soup: 161\n",
      "Fetching data for soup: 162\n",
      "Fetching data for soup: 163\n",
      "Fetching data for soup: 164\n",
      "Fetching data for soup: 165\n",
      "Fetching data for soup: 166\n",
      "Fetching data for soup: 167\n",
      "Fetching data for soup: 168\n",
      "Fetching data for soup: 169\n",
      "Fetching data for soup: 170\n",
      "Fetching data for soup: 171\n",
      "Fetching data for soup: 172\n",
      "Fetching data for soup: 173\n",
      "Fetching data for soup: 174\n",
      "Fetching data for soup: 175\n",
      "Fetching data for soup: 176\n",
      "Fetching data for soup: 177\n",
      "Fetching data for soup: 178\n",
      "Fetching data for soup: 179\n",
      "Fetching data for soup: 180\n",
      "Fetching data for soup: 181\n",
      "Fetching data for soup: 182\n",
      "Fetching data for soup: 183\n",
      "Fetching data for soup: 184\n",
      "Fetching data for soup: 185\n",
      "Fetching data for soup: 186\n",
      "Fetching data for soup: 187\n",
      "Fetching data for soup: 188\n",
      "Fetching data for soup: 189\n",
      "Fetching data for soup: 190\n",
      "Fetching data for soup: 191\n",
      "Fetching data for soup: 192\n",
      "Fetching data for soup: 193\n",
      "Fetching data for soup: 194\n",
      "Fetching data for soup: 195\n",
      "Fetching data for soup: 196\n",
      "Fetching data for soup: 197\n",
      "Fetching data for soup: 198\n",
      "Fetching data for soup: 199\n",
      "Fetching data for soup: 200\n",
      "Fetching data for soup: 201\n",
      "Fetching data for soup: 202\n",
      "Fetching data for soup: 203\n",
      "Fetching data for soup: 204\n",
      "Fetching data for soup: 205\n",
      "Fetching data for soup: 206\n",
      "Fetching data for soup: 207\n",
      "Fetching data for soup: 208\n",
      "Fetching data for soup: 209\n",
      "Fetching data for soup: 210\n",
      "Fetching data for soup: 211\n",
      "Fetching data for soup: 212\n",
      "Fetching data for soup: 213\n",
      "Fetching data for soup: 214\n",
      "Fetching data for soup: 215\n",
      "Fetching data for soup: 216\n",
      "Fetching data for soup: 217\n",
      "Fetching data for soup: 218\n",
      "Fetching data for soup: 219\n",
      "Fetching data for soup: 220\n",
      "Fetching data for soup: 221\n",
      "Fetching data for soup: 222\n",
      "Fetching data for soup: 223\n",
      "Fetching data for soup: 224\n",
      "Fetching data for soup: 225\n",
      "Fetching data for soup: 226\n",
      "Fetching data for soup: 227\n",
      "Fetching data for soup: 228\n",
      "Fetching data for soup: 229\n",
      "Fetching data for soup: 230\n",
      "Fetching data for soup: 231\n",
      "Fetching data for soup: 232\n",
      "Fetching data for soup: 233\n",
      "Fetching data for soup: 234\n",
      "Fetching data for soup: 235\n",
      "Fetching data for soup: 236\n",
      "Fetching data for soup: 237\n",
      "Fetching data for soup: 238\n",
      "Fetching data for soup: 239\n",
      "Fetching data for soup: 240\n",
      "Fetching data for soup: 241\n",
      "Fetching data for soup: 242\n",
      "Fetching data for soup: 243\n",
      "Fetching data for soup: 244\n",
      "Fetching data for soup: 245\n",
      "Fetching data for soup: 246\n",
      "Fetching data for soup: 247\n",
      "Fetching data for soup: 248\n",
      "Fetching data for soup: 249\n",
      "Fetching data for soup: 250\n",
      "Fetching data for soup: 251\n",
      "Fetching data for soup: 252\n",
      "Fetching data for soup: 253\n",
      "Fetching data for soup: 254\n",
      "Fetching data for soup: 255\n",
      "Fetching data for soup: 256\n",
      "Fetching data for soup: 257\n",
      "Fetching data for soup: 258\n",
      "Fetching data for soup: 259\n",
      "Fetching data for soup: 260\n",
      "Fetching data for soup: 261\n",
      "Fetching data for soup: 262\n",
      "Fetching data for soup: 263\n",
      "Fetching data for soup: 264\n",
      "Fetching data for soup: 265\n",
      "Fetching data for soup: 266\n",
      "Fetching data for soup: 267\n",
      "Fetching data for soup: 268\n",
      "Fetching data for soup: 269\n",
      "Fetching data for soup: 270\n",
      "Fetching data for soup: 271\n",
      "Fetching data for soup: 272\n",
      "Fetching data for soup: 273\n",
      "Fetching data for soup: 274\n",
      "Fetching data for soup: 275\n",
      "Fetching data for soup: 276\n",
      "Fetching data for soup: 277\n",
      "Fetching data for soup: 278\n",
      "Fetching data for soup: 279\n",
      "Fetching data for soup: 280\n",
      "Fetching data for soup: 281\n",
      "Fetching data for soup: 282\n",
      "Fetching data for soup: 283\n",
      "Fetching data for soup: 284\n",
      "Fetching data for soup: 285\n",
      "Fetching data for soup: 286\n",
      "Fetching data for soup: 287\n",
      "Fetching data for soup: 288\n",
      "Fetching data for soup: 289\n",
      "Fetching data for soup: 290\n",
      "Fetching data for soup: 291\n",
      "Fetching data for soup: 292\n",
      "Fetching data for soup: 293\n",
      "Fetching data for soup: 294\n",
      "Fetching data for soup: 295\n",
      "Fetching data for soup: 296\n",
      "Fetching data for soup: 297\n",
      "Fetching data for soup: 298\n",
      "Fetching data for soup: 299\n",
      "Fetching data for soup: 300\n",
      "Fetching data for soup: 301\n",
      "Fetching data for soup: 302\n",
      "Fetching data for soup: 303\n",
      "Fetching data for soup: 304\n",
      "Fetching data for soup: 305\n",
      "Fetching data for soup: 306\n",
      "Fetching data for soup: 307\n",
      "Fetching data for soup: 308\n",
      "Fetching data for soup: 309\n",
      "Fetching data for soup: 310\n",
      "Fetching data for soup: 311\n",
      "Fetching data for soup: 312\n",
      "Fetching data for soup: 313\n",
      "Fetching data for soup: 314\n",
      "Fetching data for soup: 315\n",
      "Fetching data for soup: 316\n",
      "Fetching data for soup: 317\n",
      "Fetching data for soup: 318\n",
      "Fetching data for soup: 319\n",
      "Fetching data for soup: 320\n",
      "Fetching data for soup: 321\n",
      "Fetching data for soup: 322\n",
      "Fetching data for soup: 323\n",
      "Fetching data for soup: 324\n",
      "Fetching data for soup: 325\n",
      "Fetching data for soup: 326\n",
      "Fetching data for soup: 327\n",
      "Fetching data for soup: 328\n",
      "Fetching data for soup: 329\n",
      "Fetching data for soup: 330\n",
      "Fetching data for soup: 331\n",
      "Fetching data for soup: 332\n",
      "Fetching data for soup: 333\n",
      "Fetching data for soup: 334\n",
      "Fetching data for soup: 335\n",
      "Fetching data for soup: 336\n",
      "Fetching data for soup: 337\n",
      "Fetching data for soup: 338\n",
      "Fetching data for soup: 339\n",
      "Fetching data for soup: 340\n",
      "Fetching data for soup: 341\n",
      "Fetching data for soup: 342\n",
      "Fetching data for soup: 343\n",
      "Fetching data for soup: 344\n",
      "Fetching data for soup: 345\n",
      "Fetching data for soup: 346\n",
      "Fetching data for soup: 347\n",
      "Fetching data for soup: 348\n",
      "Fetching data for soup: 349\n",
      "Fetching data for soup: 350\n",
      "Fetching data for soup: 351\n",
      "Fetching data for soup: 352\n",
      "Fetching data for soup: 353\n",
      "Fetching data for soup: 354\n",
      "Fetching data for soup: 355\n",
      "Fetching data for soup: 356\n",
      "Fetching data for soup: 357\n",
      "Fetching data for soup: 358\n",
      "Fetching data for soup: 359\n",
      "Fetching data for soup: 360\n",
      "Fetching data for soup: 361\n",
      "Fetching data for soup: 362\n",
      "Fetching data for soup: 363\n",
      "Fetching data for soup: 364\n",
      "Fetching data for soup: 365\n",
      "Fetching data for soup: 366\n",
      "Fetching data for soup: 367\n",
      "Fetching data for soup: 368\n",
      "Fetching data for soup: 369\n",
      "Fetching data for soup: 370\n",
      "Fetching data for soup: 371\n",
      "Fetching data for soup: 372\n",
      "Fetching data for soup: 373\n",
      "Fetching data for soup: 374\n",
      "Fetching data for soup: 375\n",
      "Fetching data for soup: 376\n",
      "Fetching data for soup: 377\n",
      "Fetching data for soup: 378\n",
      "Fetching data for soup: 379\n",
      "Fetching data for soup: 380\n",
      "Fetching data for soup: 381\n",
      "Fetching data for soup: 382\n",
      "Fetching data for soup: 383\n",
      "Fetching data for soup: 384\n",
      "Fetching data for soup: 385\n",
      "Fetching data for soup: 386\n",
      "Fetching data for soup: 387\n",
      "Fetching data for soup: 388\n",
      "Fetching data for soup: 389\n",
      "Fetching data for soup: 390\n",
      "Fetching data for soup: 391\n",
      "Fetching data for soup: 392\n",
      "Fetching data for soup: 393\n",
      "Fetching data for soup: 394\n",
      "Fetching data for soup: 395\n",
      "Fetching data for soup: 396\n",
      "Fetching data for soup: 397\n",
      "Fetching data for soup: 398\n",
      "Fetching data for soup: 399\n",
      "Fetching data for soup: 400\n",
      "Fetching data for soup: 401\n",
      "Fetching data for soup: 402\n",
      "Fetching data for soup: 403\n",
      "Fetching data for soup: 404\n",
      "Fetching data for soup: 405\n",
      "Fetching data for soup: 406\n",
      "Fetching data for soup: 407\n",
      "Fetching data for soup: 408\n",
      "Fetching data for soup: 409\n",
      "Fetching data for soup: 410\n",
      "Fetching data for soup: 411\n",
      "Fetching data for soup: 412\n",
      "Fetching data for soup: 413\n",
      "Fetching data for soup: 414\n",
      "Fetching data for soup: 415\n",
      "Fetching data for soup: 416\n",
      "Fetching data for soup: 417\n",
      "Fetching data for soup: 418\n",
      "Fetching data for soup: 419\n",
      "Fetching data for soup: 420\n",
      "Fetching data for soup: 421\n",
      "Fetching data for soup: 422\n",
      "Fetching data for soup: 423\n",
      "Fetching data for soup: 424\n",
      "Fetching data for soup: 425\n",
      "Fetching data for soup: 426\n",
      "Fetching data for soup: 427\n",
      "Fetching data for soup: 428\n",
      "Fetching data for soup: 429\n",
      "Fetching data for soup: 430\n",
      "Fetching data for soup: 431\n",
      "Fetching data for soup: 432\n",
      "Fetching data for soup: 433\n",
      "Fetching data for soup: 434\n",
      "Fetching data for soup: 435\n",
      "Fetching data for soup: 436\n",
      "Fetching data for soup: 437\n",
      "Fetching data for soup: 438\n",
      "Fetching data for soup: 439\n",
      "Fetching data for soup: 440\n",
      "Fetching data for soup: 441\n",
      "Fetching data for soup: 442\n",
      "Fetching data for soup: 443\n",
      "Fetching data for soup: 444\n",
      "Fetching data for soup: 445\n",
      "Fetching data for soup: 446\n",
      "Fetching data for soup: 447\n",
      "Fetching data for soup: 448\n",
      "Fetching data for soup: 449\n",
      "Fetching data for soup: 450\n",
      "Fetching data for soup: 451\n",
      "Fetching data for soup: 452\n",
      "Fetching data for soup: 453\n",
      "Fetching data for soup: 454\n",
      "Fetching data for soup: 455\n",
      "Fetching data for soup: 456\n",
      "Fetching data for soup: 457\n",
      "Fetching data for soup: 458\n",
      "Fetching data for soup: 459\n",
      "Fetching data for soup: 460\n",
      "Fetching data for soup: 461\n",
      "Fetching data for soup: 462\n",
      "Fetching data for soup: 463\n",
      "Fetching data for soup: 464\n",
      "Fetching data for soup: 465\n",
      "Fetching data for soup: 466\n",
      "Fetching data for soup: 467\n",
      "Fetching data for soup: 468\n",
      "Fetching data for soup: 469\n",
      "Fetching data for soup: 470\n",
      "Fetching data for soup: 471\n",
      "Fetching data for soup: 472\n",
      "Fetching data for soup: 473\n",
      "Fetching data for soup: 474\n",
      "Fetching data for soup: 475\n",
      "Fetching data for soup: 476\n",
      "Fetching data for soup: 477\n",
      "Fetching data for soup: 478\n",
      "Fetching data for soup: 479\n",
      "Fetching data for soup: 480\n",
      "Fetching data for soup: 481\n",
      "Fetching data for soup: 482\n",
      "Fetching data for soup: 483\n",
      "Fetching data for soup: 484\n",
      "Fetching data for soup: 485\n",
      "Fetching data for soup: 486\n",
      "Fetching data for soup: 487\n",
      "Fetching data for soup: 488\n",
      "Fetching data for soup: 489\n",
      "Fetching data for soup: 490\n",
      "Fetching data for soup: 491\n",
      "Fetching data for soup: 492\n",
      "Fetching data for soup: 493\n",
      "Fetching data for soup: 494\n",
      "Fetching data for soup: 495\n",
      "Fetching data for soup: 496\n",
      "Fetching data for soup: 497\n",
      "Fetching data for soup: 498\n",
      "Fetching data for soup: 499\n",
      "Fetching data for soup: 500\n",
      "Fetching data for soup: 501\n",
      "Fetching data for soup: 502\n",
      "Fetching data for soup: 503\n",
      "Fetching data for soup: 504\n",
      "Fetching data for soup: 505\n",
      "Fetching data for soup: 506\n",
      "Fetching data for soup: 507\n",
      "Fetching data for soup: 508\n",
      "Fetching data for soup: 509\n",
      "Fetching data for soup: 510\n",
      "Fetching data for soup: 511\n",
      "Fetching data for soup: 512\n",
      "Fetching data for soup: 513\n",
      "Fetching data for soup: 514\n",
      "Fetching data for soup: 515\n",
      "Fetching data for soup: 516\n",
      "Fetching data for soup: 517\n",
      "Fetching data for soup: 518\n",
      "Fetching data for soup: 519\n",
      "Fetching data for soup: 520\n",
      "Fetching data for soup: 521\n",
      "Fetching data for soup: 522\n",
      "Fetching data for soup: 523\n",
      "Fetching data for soup: 524\n",
      "Fetching data for soup: 525\n",
      "Fetching data for soup: 526\n",
      "Fetching data for soup: 527\n",
      "Fetching data for soup: 528\n",
      "Fetching data for soup: 529\n",
      "Fetching data for soup: 530\n",
      "Fetching data for soup: 531\n",
      "Fetching data for soup: 532\n",
      "Fetching data for soup: 533\n",
      "Fetching data for soup: 534\n",
      "Fetching data for soup: 535\n",
      "Fetching data for soup: 536\n",
      "Fetching data for soup: 537\n",
      "Fetching data for soup: 538\n",
      "Fetching data for soup: 539\n",
      "Fetching data for soup: 540\n"
     ]
    }
   ],
   "source": [
    "url_list = get_meta_url_list()\n",
    "\n",
    "soup_list = []\n",
    "count = 1\n",
    "for url in url_list:\n",
    "    print 'Fetching data for soup: '+str(count)\n",
    "    count += 1\n",
    "    soup = get_soup_meta(url)\n",
    "    soup_list.append(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print len(soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(3000)\n",
    "with open('soup_list.pickle','wb') as handle:\n",
    "    pickle.dump(soup_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for soup 1\n",
      "Getting data for soup 2\n",
      "Getting data for soup 3\n",
      "Getting data for soup 4\n",
      "Getting data for soup 5\n",
      "Getting data for soup 6\n",
      "Getting data for soup 7\n",
      "Getting data for soup 8\n",
      "Getting data for soup 9\n",
      "Getting data for soup 10\n",
      "Getting data for soup 11\n",
      "Getting data for soup 12\n",
      "Getting data for soup 13\n",
      "Getting data for soup 14\n",
      "Getting data for soup 15\n",
      "Getting data for soup 16\n",
      "Getting data for soup 17\n",
      "Getting data for soup 18\n",
      "Getting data for soup 19\n",
      "Getting data for soup 20\n",
      "Getting data for soup 21\n",
      "Getting data for soup 22\n",
      "Getting data for soup 23\n",
      "Getting data for soup 24\n",
      "Getting data for soup 25\n",
      "Getting data for soup 26\n",
      "Getting data for soup 27\n",
      "Getting data for soup 28\n",
      "Getting data for soup 29\n",
      "Getting data for soup 30\n",
      "Getting data for soup 31\n",
      "Getting data for soup 32\n",
      "Getting data for soup 33\n",
      "Getting data for soup 34\n",
      "Getting data for soup 35\n",
      "Getting data for soup 36\n",
      "Getting data for soup 37\n",
      "Getting data for soup 38\n",
      "Getting data for soup 39\n",
      "Getting data for soup 40\n",
      "Getting data for soup 41\n",
      "Getting data for soup 42\n",
      "Getting data for soup 43\n",
      "Getting data for soup 44\n",
      "Getting data for soup 45\n",
      "Getting data for soup 46\n",
      "Getting data for soup 47\n",
      "Getting data for soup 48\n",
      "Getting data for soup 49\n",
      "Getting data for soup 50\n",
      "Getting data for soup 51\n",
      "Getting data for soup 52\n",
      "Getting data for soup 53\n",
      "Getting data for soup 54\n",
      "Getting data for soup 55\n",
      "Getting data for soup 56\n",
      "Getting data for soup 57\n",
      "Getting data for soup 58\n",
      "Getting data for soup 59\n",
      "Getting data for soup 60\n",
      "Getting data for soup 61\n",
      "Getting data for soup 62\n",
      "Getting data for soup 63\n",
      "Getting data for soup 64\n",
      "Getting data for soup 65\n",
      "Getting data for soup 66\n",
      "Getting data for soup 67\n",
      "Getting data for soup 68\n",
      "Getting data for soup 69\n",
      "Getting data for soup 70\n",
      "Getting data for soup 71\n",
      "Getting data for soup 72\n",
      "Getting data for soup 73\n",
      "Getting data for soup 74\n",
      "Getting data for soup 75\n",
      "Getting data for soup 76\n",
      "Getting data for soup 77\n",
      "Getting data for soup 78\n",
      "Getting data for soup 79\n",
      "Getting data for soup 80\n",
      "Getting data for soup 81\n",
      "Getting data for soup 82\n",
      "Getting data for soup 83\n",
      "Getting data for soup 84\n",
      "Getting data for soup 85\n",
      "Getting data for soup 86\n",
      "Getting data for soup 87\n",
      "Getting data for soup 88\n",
      "Getting data for soup 89\n",
      "Getting data for soup 90\n",
      "Getting data for soup 91\n",
      "Getting data for soup 92\n",
      "Getting data for soup 93\n",
      "Getting data for soup 94\n",
      "Getting data for soup 95\n",
      "Getting data for soup 96\n",
      "Getting data for soup 97\n",
      "Getting data for soup 98\n",
      "Getting data for soup 99\n",
      "Getting data for soup 100\n",
      "Getting data for soup 101\n",
      "Getting data for soup 102\n",
      "Getting data for soup 103\n",
      "Getting data for soup 104\n",
      "Getting data for soup 105\n",
      "Getting data for soup 106\n",
      "Getting data for soup 107\n",
      "Getting data for soup 108\n",
      "Getting data for soup 109\n",
      "Getting data for soup 110\n",
      "Getting data for soup 111\n",
      "Getting data for soup 112\n",
      "Getting data for soup 113\n",
      "Getting data for soup 114\n",
      "Getting data for soup 115\n",
      "Getting data for soup 116\n",
      "Getting data for soup 117\n",
      "Getting data for soup 118\n",
      "Getting data for soup 119\n",
      "Getting data for soup 120\n",
      "Getting data for soup 121\n",
      "Getting data for soup 122\n",
      "Getting data for soup 123\n",
      "Getting data for soup 124\n",
      "Getting data for soup 125\n",
      "Getting data for soup 126\n",
      "Getting data for soup 127\n",
      "Getting data for soup 128\n",
      "Getting data for soup 129\n",
      "Getting data for soup 130\n",
      "Getting data for soup 131\n",
      "Getting data for soup 132\n",
      "Getting data for soup 133\n",
      "Getting data for soup 134\n",
      "Getting data for soup 135\n",
      "Getting data for soup 136\n",
      "Getting data for soup 137\n",
      "Getting data for soup 138\n",
      "Getting data for soup 139\n",
      "Getting data for soup 140\n",
      "Getting data for soup 141\n",
      "Getting data for soup 142\n",
      "Getting data for soup 143\n",
      "Getting data for soup 144\n",
      "Getting data for soup 145\n",
      "Getting data for soup 146\n",
      "Getting data for soup 147\n",
      "Getting data for soup 148\n",
      "Getting data for soup 149\n",
      "Getting data for soup 150\n",
      "Getting data for soup 151\n",
      "Getting data for soup 152\n",
      "Getting data for soup 153\n",
      "Getting data for soup 154\n",
      "Getting data for soup 155\n",
      "Getting data for soup 156\n",
      "Getting data for soup 157\n",
      "Getting data for soup 158\n",
      "Getting data for soup 159\n",
      "Getting data for soup 160\n",
      "Getting data for soup 161\n",
      "Getting data for soup 162\n",
      "Getting data for soup 163\n",
      "Getting data for soup 164\n",
      "Getting data for soup 165\n",
      "Getting data for soup 166\n",
      "Getting data for soup 167\n",
      "Getting data for soup 168\n",
      "Getting data for soup 169\n",
      "Getting data for soup 170\n",
      "Getting data for soup 171\n",
      "Getting data for soup 172\n",
      "Getting data for soup 173\n",
      "Getting data for soup 174\n",
      "Getting data for soup 175\n",
      "Getting data for soup 176\n",
      "Getting data for soup 177\n",
      "Getting data for soup 178\n",
      "Getting data for soup 179\n",
      "Getting data for soup 180\n",
      "Getting data for soup 181\n",
      "Getting data for soup 182\n",
      "Getting data for soup 183\n",
      "Getting data for soup 184\n",
      "Getting data for soup 185\n",
      "Getting data for soup 186\n",
      "Getting data for soup 187\n",
      "Getting data for soup 188\n",
      "Getting data for soup 189\n",
      "Getting data for soup 190\n",
      "Getting data for soup 191\n",
      "Getting data for soup 192\n",
      "Getting data for soup 193\n",
      "Getting data for soup 194\n",
      "Getting data for soup 195\n",
      "Getting data for soup 196\n",
      "Getting data for soup 197\n",
      "Getting data for soup 198\n",
      "Getting data for soup 199\n",
      "Getting data for soup 200\n",
      "Getting data for soup 201\n",
      "Getting data for soup 202\n",
      "Getting data for soup 203\n",
      "Getting data for soup 204\n",
      "Getting data for soup 205\n",
      "Getting data for soup 206\n",
      "Getting data for soup 207\n",
      "Getting data for soup 208\n",
      "Getting data for soup 209\n",
      "Getting data for soup 210\n",
      "Getting data for soup 211\n",
      "Getting data for soup 212\n",
      "Getting data for soup 213\n",
      "Getting data for soup 214\n",
      "Getting data for soup 215\n",
      "Getting data for soup 216\n",
      "Getting data for soup 217\n",
      "Getting data for soup 218\n",
      "Getting data for soup 219\n",
      "Getting data for soup 220\n",
      "Getting data for soup 221\n",
      "Getting data for soup 222\n",
      "Getting data for soup 223\n",
      "Getting data for soup 224\n",
      "Getting data for soup 225\n",
      "Getting data for soup 226\n",
      "Getting data for soup 227\n",
      "Getting data for soup 228\n",
      "Getting data for soup 229\n",
      "Getting data for soup 230\n",
      "Getting data for soup 231\n",
      "Getting data for soup 232\n",
      "Getting data for soup 233\n",
      "Getting data for soup 234\n",
      "Getting data for soup 235\n",
      "Getting data for soup 236\n",
      "Getting data for soup 237\n",
      "Getting data for soup 238\n",
      "Getting data for soup 239\n",
      "Getting data for soup 240\n",
      "Getting data for soup 241\n",
      "Getting data for soup 242\n",
      "Getting data for soup 243\n",
      "Getting data for soup 244\n",
      "Getting data for soup 245\n",
      "Getting data for soup 246\n",
      "Getting data for soup 247\n",
      "Getting data for soup 248\n",
      "Getting data for soup 249\n",
      "Getting data for soup 250\n",
      "Getting data for soup 251\n",
      "Getting data for soup 252\n",
      "Getting data for soup 253\n",
      "Getting data for soup 254\n",
      "Getting data for soup 255\n",
      "Getting data for soup 256\n",
      "Getting data for soup 257\n",
      "Getting data for soup 258\n",
      "Getting data for soup 259\n",
      "Getting data for soup 260\n",
      "Getting data for soup 261\n",
      "Getting data for soup 262\n",
      "Getting data for soup 263\n",
      "Getting data for soup 264\n",
      "Getting data for soup 265\n",
      "Getting data for soup 266\n",
      "Getting data for soup 267\n",
      "Getting data for soup 268\n",
      "Getting data for soup 269\n",
      "Getting data for soup 270\n",
      "Getting data for soup 271\n",
      "Getting data for soup 272\n",
      "Getting data for soup 273\n",
      "Getting data for soup 274\n",
      "Getting data for soup 275\n",
      "Getting data for soup 276\n",
      "Getting data for soup 277\n",
      "Getting data for soup 278\n",
      "Getting data for soup 279\n",
      "Getting data for soup 280\n",
      "Getting data for soup 281\n",
      "Getting data for soup 282\n",
      "Getting data for soup 283\n",
      "Getting data for soup 284\n",
      "Getting data for soup 285\n",
      "Getting data for soup 286\n",
      "Getting data for soup 287\n",
      "Getting data for soup 288\n",
      "Getting data for soup 289\n",
      "Getting data for soup 290\n",
      "Getting data for soup 291\n",
      "Getting data for soup 292\n",
      "Getting data for soup 293\n",
      "Getting data for soup 294\n",
      "Getting data for soup 295\n",
      "Getting data for soup 296\n",
      "Getting data for soup 297\n",
      "Getting data for soup 298\n",
      "Getting data for soup 299\n",
      "Getting data for soup 300\n",
      "Getting data for soup 301\n",
      "Getting data for soup 302\n",
      "Getting data for soup 303\n",
      "Getting data for soup 304\n",
      "Getting data for soup 305\n",
      "Getting data for soup 306\n",
      "Getting data for soup 307\n",
      "Getting data for soup 308\n",
      "Getting data for soup 309\n",
      "Getting data for soup 310\n",
      "Getting data for soup 311\n",
      "Getting data for soup 312\n",
      "Getting data for soup 313\n",
      "Getting data for soup 314\n",
      "Getting data for soup 315\n",
      "Getting data for soup 316\n",
      "Getting data for soup 317\n",
      "Getting data for soup 318\n",
      "Getting data for soup 319\n",
      "Getting data for soup 320\n",
      "Getting data for soup 321\n",
      "Getting data for soup 322\n",
      "Getting data for soup 323\n",
      "Getting data for soup 324\n",
      "Getting data for soup 325\n",
      "Getting data for soup 326\n",
      "Getting data for soup 327\n",
      "Getting data for soup 328\n",
      "Getting data for soup 329\n",
      "Getting data for soup 330\n",
      "Getting data for soup 331\n",
      "Getting data for soup 332\n",
      "Getting data for soup 333\n",
      "Getting data for soup 334\n",
      "Getting data for soup 335\n",
      "Getting data for soup 336\n",
      "Getting data for soup 337\n",
      "Getting data for soup 338\n",
      "Getting data for soup 339\n",
      "Getting data for soup 340\n",
      "Getting data for soup 341\n",
      "Getting data for soup 342\n",
      "Getting data for soup 343\n",
      "Getting data for soup 344\n",
      "Getting data for soup 345\n",
      "Getting data for soup 346\n",
      "Getting data for soup 347\n",
      "Getting data for soup 348\n",
      "Getting data for soup 349\n",
      "Getting data for soup 350\n",
      "Getting data for soup 351\n",
      "Getting data for soup 352\n",
      "Getting data for soup 353\n",
      "Getting data for soup 354\n",
      "Getting data for soup 355\n",
      "Getting data for soup 356\n",
      "Getting data for soup 357\n",
      "Getting data for soup 358\n",
      "Getting data for soup 359\n",
      "Getting data for soup 360\n",
      "Getting data for soup 361\n",
      "Getting data for soup 362\n",
      "Getting data for soup 363\n",
      "Getting data for soup 364\n",
      "Getting data for soup 365\n",
      "Getting data for soup 366\n",
      "Getting data for soup 367\n",
      "Getting data for soup 368\n",
      "Getting data for soup 369\n",
      "Getting data for soup 370\n",
      "Getting data for soup 371\n",
      "Getting data for soup 372\n",
      "Getting data for soup 373\n",
      "Getting data for soup 374\n",
      "Getting data for soup 375\n",
      "Getting data for soup 376\n",
      "Getting data for soup 377\n",
      "Getting data for soup 378\n",
      "Getting data for soup 379\n",
      "Getting data for soup 380\n",
      "Getting data for soup 381\n",
      "Getting data for soup 382\n",
      "Getting data for soup 383\n",
      "Getting data for soup 384\n",
      "Getting data for soup 385\n",
      "Getting data for soup 386\n",
      "Getting data for soup 387\n",
      "Getting data for soup 388\n",
      "Getting data for soup 389\n",
      "Getting data for soup 390\n",
      "Getting data for soup 391\n",
      "Getting data for soup 392\n",
      "Getting data for soup 393\n",
      "Getting data for soup 394\n",
      "Getting data for soup 395\n",
      "Getting data for soup 396\n",
      "Getting data for soup 397\n",
      "Getting data for soup 398\n",
      "Getting data for soup 399\n",
      "Getting data for soup 400\n",
      "Getting data for soup 401\n",
      "Getting data for soup 402\n",
      "Getting data for soup 403\n",
      "Getting data for soup 404\n",
      "Getting data for soup 405\n",
      "Getting data for soup 406\n",
      "Getting data for soup 407\n",
      "Getting data for soup 408\n",
      "Getting data for soup 409\n",
      "Getting data for soup 410\n",
      "Getting data for soup 411\n",
      "Getting data for soup 412\n",
      "Getting data for soup 413\n",
      "Getting data for soup 414\n",
      "Getting data for soup 415\n",
      "Getting data for soup 416\n",
      "Getting data for soup 417\n",
      "Getting data for soup 418\n",
      "Getting data for soup 419\n",
      "Getting data for soup 420\n",
      "Getting data for soup 421\n",
      "Getting data for soup 422\n",
      "Getting data for soup 423\n",
      "Getting data for soup 424\n",
      "Getting data for soup 425\n",
      "Getting data for soup 426\n",
      "Getting data for soup 427\n",
      "Getting data for soup 428\n",
      "Getting data for soup 429\n",
      "Getting data for soup 430\n",
      "Getting data for soup 431\n",
      "Getting data for soup 432\n",
      "Getting data for soup 433\n",
      "Getting data for soup 434\n",
      "Getting data for soup 435\n",
      "Getting data for soup 436\n",
      "Getting data for soup 437\n",
      "Getting data for soup 438\n",
      "Getting data for soup 439\n",
      "Getting data for soup 440\n",
      "Getting data for soup 441\n",
      "Getting data for soup 442\n",
      "Getting data for soup 443\n",
      "Getting data for soup 444\n",
      "Getting data for soup 445\n",
      "Getting data for soup 446\n",
      "Getting data for soup 447\n",
      "Getting data for soup 448\n",
      "Getting data for soup 449\n",
      "Getting data for soup 450\n",
      "Getting data for soup 451\n",
      "Getting data for soup 452\n",
      "Getting data for soup 453\n",
      "Getting data for soup 454\n",
      "Getting data for soup 455\n",
      "Getting data for soup 456\n",
      "Getting data for soup 457\n",
      "Getting data for soup 458\n",
      "Getting data for soup 459\n",
      "Getting data for soup 460\n",
      "Getting data for soup 461\n",
      "Getting data for soup 462\n",
      "Getting data for soup 463\n",
      "Getting data for soup 464\n",
      "Getting data for soup 465\n",
      "Getting data for soup 466\n",
      "Getting data for soup 467\n",
      "Getting data for soup 468\n",
      "Getting data for soup 469\n",
      "Getting data for soup 470\n",
      "Getting data for soup 471\n",
      "Getting data for soup 472\n",
      "Getting data for soup 473\n",
      "Getting data for soup 474\n",
      "Getting data for soup 475\n",
      "Getting data for soup 476\n",
      "Getting data for soup 477\n",
      "Getting data for soup 478\n",
      "Getting data for soup 479\n",
      "Getting data for soup 480\n",
      "Getting data for soup 481\n",
      "Getting data for soup 482\n",
      "Getting data for soup 483\n",
      "Getting data for soup 484\n",
      "Getting data for soup 485\n",
      "Getting data for soup 486\n",
      "Getting data for soup 487\n",
      "Getting data for soup 488\n",
      "Getting data for soup 489\n",
      "Getting data for soup 490\n",
      "Getting data for soup 491\n",
      "Getting data for soup 492\n",
      "Getting data for soup 493\n",
      "Getting data for soup 494\n",
      "Getting data for soup 495\n",
      "Getting data for soup 496\n",
      "Getting data for soup 497\n",
      "Getting data for soup 498\n",
      "Getting data for soup 499\n",
      "Getting data for soup 500\n",
      "Getting data for soup 501\n",
      "Getting data for soup 502\n",
      "Getting data for soup 503\n",
      "Getting data for soup 504\n",
      "Getting data for soup 505\n",
      "Getting data for soup 506\n",
      "Getting data for soup 507\n",
      "Getting data for soup 508\n",
      "Getting data for soup 509\n",
      "Getting data for soup 510\n",
      "Getting data for soup 511\n",
      "Getting data for soup 512\n",
      "Getting data for soup 513\n",
      "Getting data for soup 514\n",
      "Getting data for soup 515\n",
      "Getting data for soup 516\n",
      "Getting data for soup 517\n",
      "Getting data for soup 518\n",
      "Getting data for soup 519\n",
      "Getting data for soup 520\n",
      "Getting data for soup 521\n",
      "Getting data for soup 522\n",
      "Getting data for soup 523\n",
      "Getting data for soup 524\n",
      "Getting data for soup 525\n",
      "Getting data for soup 526\n",
      "Getting data for soup 527\n",
      "Getting data for soup 528\n",
      "Getting data for soup 529\n",
      "Getting data for soup 530\n",
      "Getting data for soup 531\n",
      "Getting data for soup 532\n",
      "Getting data for soup 533\n",
      "Getting data for soup 534\n",
      "Getting data for soup 535\n",
      "Getting data for soup 536\n",
      "Getting data for soup 537\n",
      "Getting data for soup 538\n",
      "Getting data for soup 539\n",
      "Getting data for soup 540\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "meta_ratings_dict = {}\n",
    "\n",
    "for soup in soup_list:\n",
    "    print 'Getting data for soup ' + str(count)\n",
    "    count += 1\n",
    "    for movie in soup.find_all('div', class_='basic_stat product_score brief_metascore'):\n",
    "        rating = movie.text.strip()\n",
    "        parent = movie.find_parent('div')\n",
    "        title = parent.find(class_='basic_stat product_title').text.strip()\n",
    "        meta_ratings_dict[title] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('meta_ratings_dict.pickle','wb') as handle:\n",
    "    pickle.dump(meta_ratings_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print len(soup_list)\n",
    "# print soup_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(soup_list1)\n",
    "# print len(soup_list2_1)\n",
    "# print '~~~'\n",
    "# empty_soups1 = [s for s in soup_list1 if s == None]\n",
    "# print len(empty_soups1)\n",
    "# empty_soups2 = [s for s in soup_list2_1 if s == None]\n",
    "# print len(empty_soups2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print soup_list1[:10]\n",
    "# print soup_list2_1[:10]\n",
    "# soup_list_tot = soup_list1.extend(soup_list2_1)\n",
    "# print soup_list_tot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7746\n"
     ]
    }
   ],
   "source": [
    "# small = {k: meta_ratings_dict[k] for k in meta_ratings_dict.keys()[:10]}\n",
    "# print small\n",
    "print len(meta_ratings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_dicts(*dict_args):\n",
    "    '''\n",
    "    Given any number of dicts, shallow copy and merge into a new dict,\n",
    "    precedence goes to key value pairs in latter dicts.\n",
    "    '''\n",
    "    result = {}\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = pd.Series(meta_ratings_dict)\n",
    "# for d in meta_ratings[:3]:\n",
    "#     temp = pd.DataFrame(d.items(), columns=['movie title', 'meta_rating'])\n",
    "#     ratings.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#Horror    42\n",
       "$9.99      68\n",
       "$pent      34\n",
       "'71        83\n",
       "'R Xmas    55\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratingsdf = pd.DataFrame(ratings, index=ratings.index, columns = ['meta_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#Horror</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$9.99</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$pent</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'71</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'R Xmas</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        meta_rating\n",
       "#Horror          42\n",
       "$9.99            68\n",
       "$pent            34\n",
       "'71              83\n",
       "'R Xmas          55"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv('csv/merged_table_4_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distributor</th>\n",
       "      <th>domestic total gross</th>\n",
       "      <th>genre</th>\n",
       "      <th>movie title</th>\n",
       "      <th>movieid</th>\n",
       "      <th>number of theaters</th>\n",
       "      <th>opening weekend revenue</th>\n",
       "      <th>production budget</th>\n",
       "      <th>rating</th>\n",
       "      <th>release date</th>\n",
       "      <th>runtime (mins)</th>\n",
       "      <th>time in theaters (days)</th>\n",
       "      <th>release month</th>\n",
       "      <th>decay rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orion Pictures</td>\n",
       "      <td>90944400.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Dirty Rotten Scoundrels</td>\n",
       "      <td>1</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>8129500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG</td>\n",
       "      <td>1988-12-16</td>\n",
       "      <td>110.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.171526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fox</td>\n",
       "      <td>252358600.0</td>\n",
       "      <td>Action Thriller</td>\n",
       "      <td>Speed</td>\n",
       "      <td>2</td>\n",
       "      <td>2169.0</td>\n",
       "      <td>30088300.0</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1994-06-10</td>\n",
       "      <td>116.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.181872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paramount</td>\n",
       "      <td>48884600.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>The Out-of-Towners</td>\n",
       "      <td>3</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>14084800.0</td>\n",
       "      <td>75000000.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>1999-04-02</td>\n",
       "      <td>90.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.169169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universal</td>\n",
       "      <td>39263600.0</td>\n",
       "      <td>War Romance</td>\n",
       "      <td>Captain Corelli's Mandolin</td>\n",
       "      <td>4</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>11081500.0</td>\n",
       "      <td>57000000.0</td>\n",
       "      <td>R</td>\n",
       "      <td>2001-08-17</td>\n",
       "      <td>129.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.265453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paramount</td>\n",
       "      <td>108640100.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Planes, Trains and Automobiles</td>\n",
       "      <td>5</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>15596500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>1987-11-25</td>\n",
       "      <td>92.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.189091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distributor  domestic total gross            genre  \\\n",
       "0  Orion Pictures            90944400.0           Comedy   \n",
       "1             Fox           252358600.0  Action Thriller   \n",
       "2       Paramount            48884600.0           Comedy   \n",
       "3       Universal            39263600.0      War Romance   \n",
       "4       Paramount           108640100.0           Comedy   \n",
       "\n",
       "                      movie title  movieid  number of theaters  \\\n",
       "0         Dirty Rotten Scoundrels        1              1515.0   \n",
       "1                           Speed        2              2169.0   \n",
       "2              The Out-of-Towners        3              2128.0   \n",
       "3      Captain Corelli's Mandolin        4              1612.0   \n",
       "4  Planes, Trains and Automobiles        5              1684.0   \n",
       "\n",
       "   opening weekend revenue  production budget rating release date  \\\n",
       "0                8129500.0                NaN     PG   1988-12-16   \n",
       "1               30088300.0         30000000.0      R   1994-06-10   \n",
       "2               14084800.0         75000000.0  PG-13   1999-04-02   \n",
       "3               11081500.0         57000000.0      R   2001-08-17   \n",
       "4               15596500.0                NaN      R   1987-11-25   \n",
       "\n",
       "   runtime (mins)  time in theaters (days)  release month  decay rate  \n",
       "0           110.0                     56.0           12.0   -0.171526  \n",
       "1           116.0                     70.0            6.0   -0.181872  \n",
       "2            90.0                    105.0            4.0   -0.169169  \n",
       "3           129.0                     63.0            8.0   -0.265453  \n",
       "4            92.0                     70.0           11.0   -0.189091  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moviedf = pd.merge(movie_data, ratingsdf, left_on='movie title', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distributor</th>\n",
       "      <th>domestic total gross</th>\n",
       "      <th>genre</th>\n",
       "      <th>movie title</th>\n",
       "      <th>movieid</th>\n",
       "      <th>number of theaters</th>\n",
       "      <th>opening weekend revenue</th>\n",
       "      <th>production budget</th>\n",
       "      <th>rating</th>\n",
       "      <th>release date</th>\n",
       "      <th>runtime (mins)</th>\n",
       "      <th>time in theaters (days)</th>\n",
       "      <th>release month</th>\n",
       "      <th>decay rate</th>\n",
       "      <th>meta_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orion Pictures</td>\n",
       "      <td>90944400.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Dirty Rotten Scoundrels</td>\n",
       "      <td>1</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>8129500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG</td>\n",
       "      <td>1988-12-16</td>\n",
       "      <td>110.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.171526</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fox</td>\n",
       "      <td>252358600.0</td>\n",
       "      <td>Action Thriller</td>\n",
       "      <td>Speed</td>\n",
       "      <td>2</td>\n",
       "      <td>2169.0</td>\n",
       "      <td>30088300.0</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1994-06-10</td>\n",
       "      <td>116.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.181872</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paramount</td>\n",
       "      <td>48884600.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>The Out-of-Towners</td>\n",
       "      <td>3</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>14084800.0</td>\n",
       "      <td>75000000.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>1999-04-02</td>\n",
       "      <td>90.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.169169</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universal</td>\n",
       "      <td>39263600.0</td>\n",
       "      <td>War Romance</td>\n",
       "      <td>Captain Corelli's Mandolin</td>\n",
       "      <td>4</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>11081500.0</td>\n",
       "      <td>57000000.0</td>\n",
       "      <td>R</td>\n",
       "      <td>2001-08-17</td>\n",
       "      <td>129.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.265453</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paramount</td>\n",
       "      <td>108640100.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Planes, Trains and Automobiles</td>\n",
       "      <td>5</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>15596500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>1987-11-25</td>\n",
       "      <td>92.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.189091</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distributor  domestic total gross            genre  \\\n",
       "0  Orion Pictures            90944400.0           Comedy   \n",
       "1             Fox           252358600.0  Action Thriller   \n",
       "2       Paramount            48884600.0           Comedy   \n",
       "3       Universal            39263600.0      War Romance   \n",
       "4       Paramount           108640100.0           Comedy   \n",
       "\n",
       "                      movie title  movieid  number of theaters  \\\n",
       "0         Dirty Rotten Scoundrels        1              1515.0   \n",
       "1                           Speed        2              2169.0   \n",
       "2              The Out-of-Towners        3              2128.0   \n",
       "3      Captain Corelli's Mandolin        4              1612.0   \n",
       "4  Planes, Trains and Automobiles        5              1684.0   \n",
       "\n",
       "   opening weekend revenue  production budget rating release date  \\\n",
       "0                8129500.0                NaN     PG   1988-12-16   \n",
       "1               30088300.0         30000000.0      R   1994-06-10   \n",
       "2               14084800.0         75000000.0  PG-13   1999-04-02   \n",
       "3               11081500.0         57000000.0      R   2001-08-17   \n",
       "4               15596500.0                NaN      R   1987-11-25   \n",
       "\n",
       "   runtime (mins)  time in theaters (days)  release month  decay rate  \\\n",
       "0           110.0                     56.0           12.0   -0.171526   \n",
       "1           116.0                     70.0            6.0   -0.181872   \n",
       "2            90.0                    105.0            4.0   -0.169169   \n",
       "3           129.0                     63.0            8.0   -0.265453   \n",
       "4            92.0                     70.0           11.0   -0.189091   \n",
       "\n",
       "  meta_rating  \n",
       "0          68  \n",
       "1          78  \n",
       "2          33  \n",
       "3          36  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distributor                3643\n",
       "domestic total gross       3643\n",
       "genre                      3643\n",
       "movie title                3642\n",
       "movieid                    3643\n",
       "number of theaters         3616\n",
       "opening weekend revenue    3242\n",
       "production budget          1994\n",
       "rating                     3643\n",
       "release date               3643\n",
       "runtime (mins)             3642\n",
       "time in theaters (days)    3643\n",
       "release month              3643\n",
       "decay rate                 3643\n",
       "meta_rating                2475\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviedf.count(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distributor</th>\n",
       "      <th>domestic total gross</th>\n",
       "      <th>genre</th>\n",
       "      <th>movie title</th>\n",
       "      <th>movieid</th>\n",
       "      <th>number of theaters</th>\n",
       "      <th>opening weekend revenue</th>\n",
       "      <th>production budget</th>\n",
       "      <th>rating</th>\n",
       "      <th>release date</th>\n",
       "      <th>runtime (mins)</th>\n",
       "      <th>time in theaters (days)</th>\n",
       "      <th>release month</th>\n",
       "      <th>decay rate</th>\n",
       "      <th>meta_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orion Pictures</td>\n",
       "      <td>90944400.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Dirty Rotten Scoundrels</td>\n",
       "      <td>1</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>8129500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG</td>\n",
       "      <td>1988-12-16</td>\n",
       "      <td>110.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.171526</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fox</td>\n",
       "      <td>252358600.0</td>\n",
       "      <td>Action Thriller</td>\n",
       "      <td>Speed</td>\n",
       "      <td>2</td>\n",
       "      <td>2169.0</td>\n",
       "      <td>30088300.0</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1994-06-10</td>\n",
       "      <td>116.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.181872</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paramount</td>\n",
       "      <td>48884600.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>The Out-of-Towners</td>\n",
       "      <td>3</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>14084800.0</td>\n",
       "      <td>75000000.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>1999-04-02</td>\n",
       "      <td>90.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.169169</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universal</td>\n",
       "      <td>39263600.0</td>\n",
       "      <td>War Romance</td>\n",
       "      <td>Captain Corelli's Mandolin</td>\n",
       "      <td>4</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>11081500.0</td>\n",
       "      <td>57000000.0</td>\n",
       "      <td>R</td>\n",
       "      <td>2001-08-17</td>\n",
       "      <td>129.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.265453</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DreamWorks</td>\n",
       "      <td>55006600.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Head of State</td>\n",
       "      <td>7</td>\n",
       "      <td>2256.0</td>\n",
       "      <td>19482600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>2003-03-28</td>\n",
       "      <td>95.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.114673</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distributor  domestic total gross            genre  \\\n",
       "0  Orion Pictures            90944400.0           Comedy   \n",
       "1             Fox           252358600.0  Action Thriller   \n",
       "2       Paramount            48884600.0           Comedy   \n",
       "3       Universal            39263600.0      War Romance   \n",
       "6      DreamWorks            55006600.0           Comedy   \n",
       "\n",
       "                  movie title  movieid  number of theaters  \\\n",
       "0     Dirty Rotten Scoundrels        1              1515.0   \n",
       "1                       Speed        2              2169.0   \n",
       "2          The Out-of-Towners        3              2128.0   \n",
       "3  Captain Corelli's Mandolin        4              1612.0   \n",
       "6               Head of State        7              2256.0   \n",
       "\n",
       "   opening weekend revenue  production budget rating release date  \\\n",
       "0                8129500.0                NaN     PG   1988-12-16   \n",
       "1               30088300.0         30000000.0      R   1994-06-10   \n",
       "2               14084800.0         75000000.0  PG-13   1999-04-02   \n",
       "3               11081500.0         57000000.0      R   2001-08-17   \n",
       "6               19482600.0                NaN  PG-13   2003-03-28   \n",
       "\n",
       "   runtime (mins)  time in theaters (days)  release month  decay rate  \\\n",
       "0           110.0                     56.0           12.0   -0.171526   \n",
       "1           116.0                     70.0            6.0   -0.181872   \n",
       "2            90.0                    105.0            4.0   -0.169169   \n",
       "3           129.0                     63.0            8.0   -0.265453   \n",
       "6            95.0                    112.0            3.0   -0.114673   \n",
       "\n",
       "  meta_rating  \n",
       "0          68  \n",
       "1          78  \n",
       "2          33  \n",
       "3          36  \n",
       "6          44  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviedf_r = moviedf[pd.notnull(moviedf['meta_rating'])]\n",
    "moviedf_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distributor                2475\n",
       "domestic total gross       2475\n",
       "genre                      2475\n",
       "movie title                2475\n",
       "movieid                    2475\n",
       "number of theaters         2469\n",
       "opening weekend revenue    2183\n",
       "production budget          1703\n",
       "rating                     2475\n",
       "release date               2475\n",
       "runtime (mins)             2474\n",
       "time in theaters (days)    2475\n",
       "release month              2475\n",
       "decay rate                 2475\n",
       "meta_rating                2475\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviedf_r.count(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moviedf_r.to_csv('csv/moviedf_with_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moviedf.to_csv('csv/moviedf_with_null_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
